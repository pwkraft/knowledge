\section*{Appendix A: Detailed Information on Open-Ended Responses and Discursive Sophistication Components}
\renewcommand\thefigure{A.\arabic{figure}}
\renewcommand\thetable{A.\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}

\begin{figure*}[h]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/anes2012_wc.pdf}
        \caption{2012 ANES}
    \end{subfigure}%
	\begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/anes2016_wc.pdf}
        \caption{2016 ANES}
    \end{subfigure}%
    
    \begin{subfigure}[t]{0.49\textwidth}
        \centering
        \includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/yg_wc.pdf}
        \caption{2015 YouGov}
    \end{subfigure}
    \begin{subfigure}[t]{0.49\textwidth}
         \centering
         \includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/swiss_wc.pdf}
         \caption{Swiss Survey}
    \end{subfigure}
    \caption{Histograms of total word count in the collection of open-ended responses for each individual. The dashed red lines indicate the average response lengths in each survey.}\label{fig:wc}
\end{figure*}

\begin{figure}[h]\centering
\includegraphics[width=\textwidth]{/data/Dropbox/Uni/Projects/2016/knowledge/fig/anes_stm_prop.pdf}
\caption{Estimated topic proportions in the 2012 and 2016 ANES based on the structural topic model. See Appendix B for details on the model specification.}\label{fig:anes_stm_prop}
\end{figure}

\begin{figure}[h]\centering
\includegraphics[width=.5\textwidth]{/data/Dropbox/Uni/Projects/2016/knowledge/fig/yg_stm_prop.pdf}
\caption{Estimated topic proportions in the 2015 YouGov survey based on the structural topic model. See Appendix B for details on the model specification.}\label{fig:yg_stm_prop}
\end{figure}

\begin{figure}[h]\centering
\includegraphics[width=\textwidth]{/data/Dropbox/Uni/Projects/2016/knowledge/fig/swiss_stm_prop.pdf}
\caption{Estimated topic proportions in the Swiss survey based on the structural topic model. See Appendix B for details on the model specification.}\label{fig:swiss_stm_prop}
\end{figure}

\begin{figure*}[h]
    \centering
    \begin{subfigure}[h]{0.5\textwidth}
        \centering
        \includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/anes2012_corplot_components.pdf}
        \caption{2012 ANES}
    \end{subfigure}%
    \begin{subfigure}[h]{0.5\textwidth}
         \centering
         \includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/anes2016_corplot_components.pdf}
         \caption{2016 ANES}
    \end{subfigure}%
    
    \begin{subfigure}[h]{0.49\textwidth}
        \centering
        \includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/yg_corplot_components.pdf}
        \caption{2015 YouGov}
    \end{subfigure}
    \begin{subfigure}[h]{0.49\textwidth}
         \centering
         \includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/swiss_corplot_components.pdf}
         \caption{Swiss Survey}
    \end{subfigure}
    \caption{Correlation matrix of individual components of discursive sophistication. The plots on the diagonal display univariate densities for each component. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient.}\label{fig:components}
\end{figure*}



\clearpage
\section*{Appendix B: Pre-Processing and Topic Model Specification}
\renewcommand\thefigure{B.\arabic{figure}}
\renewcommand\thetable{B.\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}

Two components of discursive sophistication (\textit{considerations} and \textit{word choice}) rely on quantities extracted from structural topic models \citep{roberts2014structural}. As with any other text-as-data approach, a necessary first step before estimating the topic model is to pre-process the raw text and convert it into a document term matrix \citep[DTM, see for example][]{manning2008introduction}. Common pre-processing procedures include stemming and lowercasing, as well as the removal of numbers, punctuation, stopwords, and infrequent terms. However, topic models and other unsupervised learning techniques can be sensitive to these pre-processing choices \citep[c.f.,][]{denny2018text}. To address this issue, \citet{denny2018text} recommend that researchers compare DTMs under all possible pre-processing regimes. The authors propose \textit{preText scores} as a measure to quantify the extent to which varying pre-processing regimes may yield unusual results compared to a baseline without any pre-processing.

\begin{figure}[h]
\centering\includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/pretext.pdf}
    \caption{PreText analysis of pre-processing decisions of open-ended responses across all datasets. Regression coefficients display the effects of each of the six pre-processing choices on the resulting preText score.}\label{fig:pretext}
\end{figure}

Following the procedure outlined in \citet{denny2018text}, Figure~\ref{fig:pretext} displays the results of a linear model regressing preText scores resulting from all possible pre-processing regimes on each individual step for a random subset of 500 open-ended responses in each of the studies included in the analyses. Significant coefficients indicate that the topic model results my be sensitive to the respective pre-processing step. As such, removing stopwords and punctuation, as well as removing infrequent terms (at least in the 2016 ANES) might be problematic. \citet{denny2018text}, however, emphasize that the most important consideration in choosing pre-processing steps are theoretical. Given that the purpose of the topic model is to extract considerations related to political preferences, there are strong theoretical reasons to remove stopwords and punctuation from open-ended responses as they do not contain any relevant content. Furthermore, I apply lowercasing and stemming of terms to reduce resulting document term matrix to a computationally more manageable size and since these pre-processing steps should not be influential according to the preText analysis.

It is less obvious from a theoretical perspective whether to remove infrequent terms from open-ended responses, although it is preferred in order to make the estimation of the discursive sophistication components computationally efficient. Since the preText analysis for the 2016 ANES suggests that this pre-processing step might be influential, I compare discursive sophistication for both alternative regimes below \citep[c.f.,][]{denny2018text}. Before turning to this sensitivity check, however, I consider another crucial modeling choice when working with topic models: determining the total number of topics $k$ to be estimated. For all analyses reported below, the number of topics was selected using the algorithm proposed by \citet{lee2014low} and implemented in the \texttt{stm} package in \textbf{R} \citep{roberts2014stm}.\footnote{I used measures for age, gender, education, party identification, as well as an interaction between education and party identification as covariates for topic prevalence. This variable selection---with the exception of including gender---is equivalent to the procedure model specification described in \citet{roberts2014structural}.} 

\begin{figure}[h]\centering
\includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/pretext_robustness.pdf}
\caption{Robustness of discursive sophistication measure for different pre-processing choices and topic model specifications.}\label{fig:pretext_robustness}
\end{figure}

Figure~\ref{fig:pretext_robustness} examines whether the proposed measure of discursive sophistication is sensitive to the removal of infrequent terms as well as the chosen number of topics $k$. The y-axis depicts the preferred pre-processing regime including all steps discussed above while the x-axis plots results for alternative specifications. The panels on the left compare the preferred specification to discursive sophistication based on a reduced number of topics ($k=20$). The middle panels additionally include infrequent terms instead of removing them.\footnote{Calculating discursive sophistication with large numbers of topics while including infrequent terms is computationally prohibitive.} The panels on the right omit do not perform stemming as part of the pre-processing step. Across all panels, discursive sophistication scores are highly correlated and therefore insensitive to pre-processing choices and varying numbers of topics.

In summary, open-ended responses in the analyses reported below are pre-processed by stemming and lowercasing, as well as the removing numbers, punctuation, stopwords, and infrequent terms (i.e., terms that appear in fewer than 10 responses).\footnote{Prior to applying these pre-processing steps, open-ended responses in the 2012 \& 2016 ANES as well as the 2015 YouGov survey are cleaned by correcting spelling errors using an implementation of the Aspell spell-checking algorithm (\url{www.aspell.net}).} While the results discussed in the manuscript are based on this preferred specification, the substantive results are robust for alternative pre-processing regimes or varying numbers of topics.


%\clearpage
%\section*{Appendix C: Tables of Model Estimates}
%\renewcommand\thefigure{C.\arabic{figure}}
%\renewcommand\thetable{C.\arabic{table}}
%\setcounter{figure}{0}
%\setcounter{table}{0}
%
%\input{../tab/inteff}
%\input{../tab/exteff}
%\input{../tab/nonconv}
%\input{../tab/turnout}
%\input{../tab/determinants}
%\input{../tab/closing}
%\input{../tab/yg_determinants}