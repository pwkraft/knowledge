\documentclass[12pt]{article}
\usepackage[margin = 1in]{geometry}
\usepackage[USenglish]{babel}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{lscape}
\usepackage{dcolumn}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{enumerate}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{arydshln}
\usepackage{dcolumn}
\usepackage[colorlinks=true,citecolor=red!50!black,urlcolor=blue!50!black,linkcolor=red!50!black]{hyperref}

\author{Patrick W. Kraft\footnote{Ph.D. Candidate, Stony Brook University, \href{mailto:patrick.kraft@stonybrook.edu}{patrick.kraft@stonybrook.edu}.
}}

\title{Let's Talk Politics\\
%Alternative titles: Talking Politics; Looking for Answers
\large{A Naive Approach for Measuring Political Sophistication}\footnote{Previous versions of this manuscript have been presented at Polmeth 2016, MPSA 2017, EPSA 2017, and ISPP 2017.
I thank Jason Barabas, Scott Clifford, Andy Delton, Peter DeScioli, Stanley Feldman, Fabrizio Gilardi, Bill Jacoby, Jennifer Jerit, and Yanna Krupnikov for helpful comments on previous versions of this manuscript. Special thanks to C{\'e}line Colombo, Scott Clifford, and Jennifer Jerit for sharing their data. The manuscript and code are available on GitHub: \url{https://github.com/pwkraft/knowledge}.
% Additional people to mention: Kathy Dolan, Jamie Monogan
}
}
\date{}

% sans serif font
\renewcommand{\familydefault}{\sfdefault}


\begin{document}
\maketitle
\doublespacing
\thispagestyle{empty}

\begin{center}
-- WORK IN PROGRESS -- \\
PLEASE DO NOT CITE OR REDISTRIBUTE WITHOUT PERMISSION
\end{center} 

\hfill
\begin{abstract}\singlespacing
This paper proposes a simple but powerful framework to assess political sophistication in verbatim responses to open-ended survey questions using quantitative text analysis methods. The measure aims to capture the complexity of individual attitude expressions by examining their underlying number of considerations, characteristics of word choice, and the level of opinionation. I validate the approach by comparing it to conventional political knowledge metrics in multiple studies using different batteries of open-ended items. The paper proceeds to illustrate how discursive sophistication can help refine previous insights from the literature such as the oft-cited gender gap in political knowledge.
% This is just a placholder abstract for now, needs some serious revisions.
% QUESTION: measure can be based on different sets of items

%\vspace{\baselineskip}
%\noindent \textit{Keywords:} political sophistication, gender gap, measurement, open-ended responses, text analysis \\

\end{abstract}
\hfill
\newpage\setcounter{page}{1}
% REVISE: mention data sources earlier in the manuscript?
% REPLACE: "recall" instead of "factual" knowledge questions
% REVISE: work on transitions, what does each analysis bring to the table
% ADD: literature on accuracy motivation in psychology

Alarmingly high levels of voter ignorance have been one of the major recurring themes in public opinion research. Not too long ago, for example, \citet{bartels2005homer} attributed public support for the Bush administration's 2001 and 2003 tax cuts to a substantial lack of political information among voters \citep[but see][]{lupia2007were,bartels2007homer}. Similarly, Delli Carpini and Keeter's \citeyearpar{carpini1996americans} seminal book on political knowledge warned that widespread ignorance might jeopardize equal representation of citizens. Early influential scholars such as \citet{converse1964nature} also emphasized that large parts of the public lack a sufficient understanding of abstract ideological concepts and do not hold stable issue positions. Indeed, the finding that citizens know little about politics seems to go as far back in history as the systematic study of public opinion itself.

Yet, not everyone agrees with this pessimistic assessment. Indeed, there has been a lively debate about how to accurately assess political knowledge in the first place \citep[e.g.][]{mondak2000reconsidering,mondak2001asked,sturgis2008experiment,debell2013harder,pietryka2013analysis}. Most analyses rely on standard item batteries that assess individuals' factual knowledge about political institutions and officeholders \citep[e.g.,][]{carpini1996americans}. Recent research, however, points to important distinctions in types of political knowledge that have previously been disregarded \citep{barabas2014question}. Scholars furthermore argue that recall-based measures of political knowledge do not necessarily capture how people structure their attitudes and beliefs \citep[e.g.,][]{luskin1987measuring} and may not be theoretically relevant for the development of informed preferences \citep[e.g.,][]{lupia2006elitism,gilens2001political}.

% JENN: cut this para, cite gilens
%The last point raises a fundamental question about the type of knowledge that is actually necessary for outcomes we view as desirable \citep[see also][]{lupia2015uninformed}: Do citizens really need to know specific details about US political institutions in order to successfully engage in politics? For example, precise knowledge of the official term lengths of U.S. Senators can hardly be viewed as necessary to cast an informed vote between two candidates running for President. This is especially the case since voters can rely on heuristics \citep{lupia1994shortcuts} or procedural knowledge \citep{prior2008money} when forming political preferences. Factual knowledge as measured in many public opinion surveys may therefore not be an ideal indicator for citizens' competence to engage in politics.

% More direct/active language in this para:
This article develops an alternative measure of political sophistication that addresses this disconnect. Normative democratic theory suggests that voters should hold informed opinions about available candidates and relevant issues before casting a vote. Rather than relying on factual knowledge that is potentially unrelated to the task at hand, I examine how respondents discuss their political preferences and beliefs in their own words. For a given set of verbatim responses, the measure assesses political sophistication based on the number of considerations raised by individuals, the relative descriptiveness in word choice, as well as the level of opinionation. The approach is therefore \textit{naive} in that it does not presuppose pieces of information as necessary for political competence but rather examines the respondents' justification of their preferences at face value. The goal is to assess whether political attitudes relevant to perform a specific task are expressed in a more elaborate manner---a question that is not directly discernible when examining off-the-shelf factual knowledge items. %The discursive measure is therefore conceptually closer to the degree of structure and constraint in political belief systems \citep[see for example][]{tetlock1983cognitive,luskin1987measuring}. 

% TODO: revise this section, predictor part comes out of nowhere
The proposed measure is validated across multiple data sets by comparing it to conventional factual knowledge scores as predictors of competences relevant to perform political tasks. While the measures share a considerable amount of variance, they are far from equivalent. Indeed, discursive sophistication is a stronger predictor of turnout and other forms of political participation than traditional measures. After validating the measurement approach, the paper illustrates how discursive sophistication can help refine previous insights in the literature by re-examining an oft-cited finding in empirical research---the gender gap in political knowledge. Contrary to previous research, I find no evidence for such a gap based on open-ended responses. While women might score lower than men on factual knowledge about political institutions and elites, there are no differences in the complexity of expressed political attitudes. More generally, the results suggest that developing valid measures of political sophistication based on open-ended responses can provide new opportunities to examine political knowledge across time and contexts. 


\section*{Factual Knowledge and Political Competence}
%\section*{Recalling Facts Does Not Imply (Political) Competence}
% 1: gender gap is a commom phenomenon in the literature
% 2: potential explanations based on measurement
% 3: broader issue: do we need political facts or structure of belief systems? competence?
% ADD: section on the role of competences etc.
% REVISE: all tests of political knowlege should follow based on the required competences

% A lot of political science research focuses on political knowledge, but that's not really what we should care about.
% - Druckman argument: Issue of representation, why common indicators of political knowledge are insufficient. What are the alternatives? Think of attitude formation!
% - Lupia argument: identify a task and the necessary competences. Criteria to select knowledge questions are often random, not guided by theory about necessary competences. Think about what people need to do, then think about how to assess whether they can do that.

% JENN: cut both paras, they are repetitive w/ opening... maybe use some of the citations?
%A common theme in public opinion research revolves around the question whether citizens fulfill the requirements necessary to hold their elected officials accountable. Pioneered by \citet{carpini1996americans} and others, much of this inquiry has focused on individual levels of factual knowledge about political institutions and officeholders \citep[see also][]{carpini1993measuring}. For example, \citet[21]{zaller1992nature} argued that testing factual information about politics provides the best available measure of political awareness, since it ``more directly than any of the alternative measures, capture[s] what has actually gotten into peopleâ€™s minds.'' Studies in this area frequently attest that large parts of the public do not meet the standards determined by researchers. Quite contrary, the citizenry appears mostly disengaged, uninterested, and above all ill-informed about politics, which can ultimately result in unequal representation in the political system \citep[e.g.,][]{althaus1998information,kuklinski2000misinformation,gilens2001political}.

%However, this is not the only recurring theme in the literature related to citizens' level of information. Instead, there are frequent debates about the proper measurement of political knowledge. For example, \citet{krosnick2008problems} emphasized problems related to the coding rules of common recall items included in the American National Election Study, which fail to properly capture partial knowledge \citep[see also][]{gibson2009knowing,debell2013harder}. \citet{mondak2000reconsidering} raised additional concerns by showing that individual performance on political knowledge items is influenced by differential probabilities to engage in guessing \citep[see also][]{mondak2001developing,mondak2001asked,miller2008experimenting}. While the question of measurement using knowledge items is certainly an important debate with noteworthy recent contributions \citep[e.g.,][]{pietryka2013analysis}, there is a more fundamental theoretical issue related political sophistication that is frequently overlooked: \textit{What do citizens need to know in order to participate effectively in the democratic process?}

The most important task for citizens in modern democracies is to vote for candidates who represent their interests and thereby hold their elected officials accountable. Arguably, survey items measuring political knowledge should therefore cover information that is necessary and/or sufficient to perform this essential task. However, determining such a set of items proves to be extremely difficult (if not impossible), especially since there are systematic differences in types of knowledge \citep{barabas2014question} and survey questions typically cannot capture important aspects such as visual cues \citep{prior2014visual}. In conceptualizing political knowledge, \citet{barabas2014question} distinguished both a temporal dimension (i.e., whether it is static or more contemporary) as well as a topical dimension (i.e., whether it is general or more policy-specific). Importantly, varying the types of questions on these dimensions leads to different conclusions regarding the nature and determinants of political knowledge. However, even within a given category, people may disagree about which facts are important due to inherent value differences \citep[c.f.,][]{lupia2015uninformed}. As such, even if we had strong theoretical reasons to focus on a certain set of questions according to the typology developed by \citet{barabas2014question} there would still be uncertainty about the specific set of facts deemed as necessary to perform a political task. Despite these difficulties, most empirical studies simply relied on a set of off-the-shelf knowledge questions that have been used in previous research rather than justifying their choices from a theoretical perspective. As \citet[219]{lupia2006elitism} explains, ``Most political knowledge questions are not derived from a replicable or transparent logic about how their answers bear on a voter's ability to make decisions of a particular quality.'' As such, information requested in conventional survey items often have no clear relevance to political participation. 

\citet{lupia2006elitism} argues that instead of focusing on potentially irrelevant factual knowledge, researchers should concentrate on heuristics that directly help citizens to make competent political decisions or focus only on knowledge relevant to a specific task \citep[see also][]{lupia1994shortcuts,lupia2015uninformed}. After all, there is no need for individuals to know all available facts, but only to possess the skills and resources to be able to \textit{find} the information required in a specific context \citep{prior2008money}. \citet{druckman2014pathologies} makes a similar argument in a recent review of research on public opinion and democratic responsiveness. Since there is no apparent consensus about the precise measurement of political knowledge and it is unclear what information is necessary in the first place, the author proposes to direct the attention away from individual levels of political information as a measure of ``quality opinion.'' Instead, \citet[478, emphasis in the original]{druckman2014pathologies} advocates ``\textit{less} focus on the \textit{content/substance} of opinions (e.g., are they informed, constrained, based on strong frames, etc.?) and \textit{more} on the \textit{process} and specifically the \textit{motivation} that underlies the formation of those opinions.'' The framework proposed herein follows this call in attempting to measure political sophistication based on expressed attitudes related to a specific political task.


\section*{Opinion Formation and Attitude Expression}

Rather than trying to develop a new item battery that presupposes a set of facts as necessary for political competence---a task that is difficult to achieve---I propose to analyze how individuals discuss their attitudes and preferences related to a political task in their own words. Citizens have to engage in a lot of choices in democratic politics. For example, they can vote in local, state, or federal elections. Depending on the institutional setup, they may also directly decide on specific policies through referenda. In these contexts, we are often concerned whether citizens are able to make high quality decisions in accordance with their preferences. According to \citet{druckman2014pathologies}, scholars should concentrate on whether individuals are motivated to engage in accurate and objective processing when forming their opinions rather than trying to assess their level of factual knowledge. Importantly, a major approach to induce accuracy motivations discussed by \citet[478]{druckman2014pathologies} involves asking individuals to ``justify/provide reasons for one's opinions'' \citep[see also][]{tetlock1983cognitive,kunda1999motivated,redlawsk2002hot,bolsen2014influence}. Conversely, we may directly examine \textit{how} citizens justify their preferences in order to evaluate their level of sophistication in attitude expression. To the extent that respondents are motivated and able to engage in in-depth processing to form quality opinions, they should discuss multiple considerations related to a political issue and show awareness of arguments for and against certain positions.

Such a perspective resembles influential theoretical accounts of political sophistication which focus on the \textit{structure} of belief systems rather than the content (or accuracy) of related considerations. In his seminal article, \citet{converse1964nature} emphasized the importance of the level of conceptualization as the main characteristic of sophistication rather than isolated pieces of factual information. Similarly, \citet{tetlock1983cognitive} used the term \textsl{integrative complexity} to describe the degree to which considerations related to an issue are interconnected. \citet{luskin1987measuring} also defined political sophistication based on the structure of individual belief systems, arguing that they can vary on three separate dimensions: (1) their \textsl{size} -- i.e. the number of cognitions, (2) their \textsl{range} -- i.e. the dispersion of cognition over categories, and (3) their \textsl{constraint} -- i.e. the extent to which cognitions are interconnected in a meaningful way. Political sophistication, in turn, is seen as the conjunction of these dimensions: ``A person is politically sophisticated to the extent to which his or her [political belief system] is large, wide-ranging, and highly constrained.'' \citep[860]{luskin1987measuring}. These differences in sophistication should be reflected in the way individuals describe, discuss, and justify their political beliefs.

\citet{colombo2016justifications} makes a similar argument when investigating the level of competence of Swiss citizens voting in policy referenda. Examining data from thirty-four ballot decisions, the author analyzes how voters justify their individual decision in favor or against a certain policy in open-ended survey responses. More specifically, she proposes to ``consider the capacity to justify political decisions with policy-related arguments as a possible conceptualization of citizen competence in direct democracy'' \citep[3]{colombo2016justifications}. Levels of justification are thereby measured based on a manual coding of each answer's content, elaboration, and complexity. \citet{colombo2016justifications} finds that while Swiss citizens are indeed able to provide policy-related arguments to justify their decisions, their level of competence is influenced by the political context and individual resources.

Examining individual levels of justification in open-ended responses as a measure of political competence is not only applicable to referenda in direct democracies. Indeed, it can be implemented in diverse settings involving various types of political preferences. From a theoretical perspective, the same arguments regarding the structure of individual belief systems holds when examining different types of open-ended responses, for example when respondents discuss their attitudes toward candidates running for office. In order to measure sophistication and competence related to a political task of interest, I therefore propose to examine how individuals discuss and justify their related preferences in their own words instead of relying off-the-shelf knowledge items. However, manual coding of open-ended responses as employed by \citet{colombo2016justifications} is not always feasible in the context of large-scale surveys, since it can be very labor-intensive, requires a large amount of contextual knowledge, and---depending on the country---necessitates high levels of language proficiency.\footnote{The Swiss surveys in Colombo's \citeyearpar{colombo2016justifications} study were conducted in three different languages: German, French, and Italian.} Furthermore, knowledge assessments can be biased by the level of political agreement between individuals \citep{ryan2011accuracy}. As such, I now present a simple but powerful alternative approach that relies on quantitative text-analysis methods and can be applied in multiple contexts and different languages.
% ELABORATE: differentiate from manual coding of integrative complexity (labor intensive) and dictionary-based methods (focus on linguistic characteristics, which could easily conflate general eloquence)


\section*{Measuring Discursive Sophistication}

How would a politically sophisticated person who engages in in-depth processing discuss his or her views compared to a less informed individual? Consider a survey where respondents are asked to describe their attitudes toward specific policies or candidates running for office in a set of open-ended items. In such a scenario, the structure of individual political belief systems (i.e., size, range, and constraint) as well as the level of motivation to engage in accurate opinion formation should be reflected in their verbatim responses. In the following, I discuss three different attributes of open-ended survey responses that should be indicative of individual political sophistication as described by previous scholars.

First of all, sophisticated individuals should be able to elaborate more on their political attitudes. If people possess a large, wide-ranging, and constrained belief system, they should be able to recall a large number of \textit{considerations} related to political actors or issues. I rely on the structural topic model framework \citep{roberts2014structural} to extract the number of topics mentioned by each respondent in a survey.\footnote{See below for more information on the pre-processing of open-ended responses as well as the topic model specification.} First, denote $\mathcal{W}_i$ as the set of words contained in a response of individual $i$. Each word $w\in\mathcal{W}_i$ is assigned to a topic $t^* \in \{1,...,T\} $, such that $P(t^*|w,X_i) > P(t|w,X_i) \forall t\neq t^*$.\footnote{Note that $P(t|w,X_i)=\dfrac{P(w|t)P(t|X_i)}{P(w|X_i)}$. In the context of structural topic models, $X_i$ denotes the covariates used to predict individual topic prevalence \citep[see][for details]{roberts2014structural}.} In other words, each unique term in a response is assigned to the topic that has the highest likelihood of having generated that term, given the model. The set of topics that are mentioned by respondent $i$ across all words in $\mathcal{W}_i$ can then be denoted as $\mathcal{T}^*_i$ and the number of considerations can be written as:
\begin{equation}
\text{considerations}_i = \dfrac{|\mathcal{T}^*_i|}{\max_i|\mathcal{T}^*_i|}.
\end{equation}
The measure is re-scaled to range from zero to one by dividing raw count of topics by the maximum number of topics observed across individuals.

However, sophisticated respondents should not only be able to mention a larger number of raw considerations when discussing politics. The level of sophistication should also be reflected in the \textit{word choice} describing the underlying issues. Individuals who possess a wide-ranging and constrained system of beliefs should be more inclined to use terms that are highly descriptive of a given topic (e.g., the \textit{economy} or \textit{taxes}) rather than broad terms that could be attributed to any topic. Words that are very descriptive of a topic have a high likelihood to appear if that topic is mentioned. Highly descriptive word choice is therefore conceptualized as the sum of term likelihoods $P(w|t^*)$ given topic assignments over the entire set of words in $\mathcal{W}_i$:
\begin{equation}
\text{word choice}_i = \dfrac{\sum_{\mathcal{W}_i} P(w|t^*)}{\max_i\left[\sum_{\mathcal{W}_i} P(w|t^*)\right]}
\end{equation}
Again, the measure is re-scaled to range from zero to one by dividing all values by the empirical maximum observed across all individuals in the data.

Lastly, sophisticated individuals should hold opinions about each political actor or policy that they are asked to discuss. As such, shophisticates should be able to express their attitudes towards each open-ended probe in terms of both approval or disapproval. Responses that reflect high levels of sophistication should therefore display a greater level of \textit{opinionation}, which is conceptualized as the diversity of relative lengths for each open-ended response (specified as the Shannon entropy):
\begin{equation}
\text{opinionation}_i = \dfrac{-\sum_{j=1}^J p_{ij} \ln p_{ij}}{\ln J}
\end{equation}
where $p_{ij}$ is the proportion of words in the response of individual $i$ to question $j\in \{1,...,J\}$ relative to the overall size of the individuals' response. The variable ranges from 0 (only one question was answered) to 1 (all questions were answered with the same word length per answer).

Together, the three measures form a composite metric of political sophistication by calculating their respective average for each respondent. Like each individual component, the resulting \textit{discursive sophistication} score ranges from 0 to 1:
\begin{equation}
\text{discursive sophistication}_i = \tfrac{1}{3}(\text{considerations}_i + \text{word choice}_i + \text{opinionation}_i).
\end{equation}
Overall, a highly sophisticated individual can be expected to respond to a set of open-ended items by giving a more elaborate response that focuses on multiple considerations or topics using terms that are highly descriptive of each topic and addresses his or her attitudes towards all relevant political actors or policies more or less equally. It is important to note that this approach differs from recent work on sophistication in speeches and other sources of political texts \citep[e.g.,][]{spirling2016democratization,benoit2017measuring} as it explicitly tries to capture complexity independent of pure linguistic style.



\section*{An Overview of Data Sources and Open Ended Items}

The measure of discursive sophistication is validated using multiple surveys employing different sets of open-ended questions. Each data set and the respective items used to compute discursive sophistication are briefly described below. %Please refer to the appendix for more detailed information on the data and methods, such as pre-processing the verbatim responses.


\subsection*{2012 \& 2016 American National Election Study}
The main analyses are based on the 2012 and 2016 wave of the American National Election Study (ANES), which consist of a representative survey of about 5000 adults in the months before the US Presidential election in each year. About 2000 respondents in both waves participated in face-to-face interviews while the remaining respondents filled out the survey online. For the purpose of the present analyses, I rely on the pooled datasets while controlling for differences in survey mode. The measure of discursive sophistication is based on open-ended questions in which respondents were asked in the pre-election wave of the survey to list anything in particular that they like/dislike about the Democratic/Republican party as well as anything that might make them vote/not vote for either of the Presidential candidates. They were probed by the interviewer asking ``anything else?'' until the respondent answered ``no''. Overall, there are a total number of 8 open-ended responses where individuals described their beliefs and attitudes towards political actors. Individuals who did not respond to all of the open-ended items (420 in 2012; 204 in 2016), or who responded in Spanish (228 in 2012; 43 in 2016), were excluded from the analysis.\footnote{See Appendix A for more details on the structural topic model and descriptive information on the individual components of discursive sophistication.}


\subsection*{2015 YouGov Survey}
In order to replicate and extend the main analyses, I rely on a separate nationally representative survey employing an alternative set of open-ended responses. The data was collected by YouGov in December 2015 and contains responses of 1000 U.S. citizens.\footnote{See \citet{clifford2016cheating} for details on the study.} As part of this study, respondents were asked to describe their attitudes towards two prominent political issues that were discussed frequently in the media. First, they were asked in a closed format whether they favor or oppose stricter gun laws. Subsequently, they were asked to respond to the following two questions:
\begin{itemize}\setlength\itemsep{0em}
\item Still thinking about the question you just answered, what thoughts came to mind while you were answering that question? Please try to list everything that came to mind.
\item Thinking about the mass shootings that have occurred in the U.S. in the last few years, what factors do you think are responsible for the shootings?
\end{itemize}
Second, the respondents reported on their attitudes towards the Affordable Care Act in a closed format and were then asked to elaborate in their own words by answering the following questions:
\begin{itemize}\setlength\itemsep{0em}
\item Still thinking about the question you just answered, what thoughts came to mind while you were answering that question? Please try to list everything that came to mind.
\item For decades, experts have observed that the United States spends far more per person on health care than any other country. However, the U.S. falls behind on most measures of health care outcomes, such as life expectancy. What factors do you think are responsible for the state of our health care system?
\end{itemize}
Here, discursive sophistication is computed based on the verbatim responses to the four preceding questions using the same procedures described above. Compared to the open-ended likes/dislikes items included in the 2012 and 2016 ANES, the questions directly address considerations related to specific policy issues that were prominent in the political discourse at the time of the survey. Respondents who did not provide an answer to any of the open-ended questions were removed from the analysis (48).\footnote{See Appendix B for descriptive information on the individual components of discursive sophistication.}


\subsection*{Swiss Referendum Survey}
Lastly, I examine survey data on Swiss citizens justifying their vote choices on multiple referenda used in the analyses presented by \citet{colombo2016justifications}. The author compiled a data set from cross-sectional surveys that were conducted in Switzerland after national popular votes on multiple policy propositions. The original surveys were conducted as representative samples after each of thirty-four national policy votes that were held between 2008 and 2012 resulting in a total of 26,621 observations. However, respondents were only asked to justify their decision for or against a given proposition in verbatim if they participated in the vote in the first place. As such, 4,917 individuals in the data set did not provide an open-ended response. The remaining respondents were asked to describe the main reason as well as additional justifications for their decision in two separate items. As before, discursive sophistication is computed based on the verbatim responses to both questions.\footnote{See Appendix C for descriptive information on the individual components of discursive sophistication.}
% QUESTION wording for Swiss study?


\section*{Pre-Processing and Topic Model Specification}

Two components of discursive sophistication (\textit{considerations} and \textit{word choice}) rely on quantities extracted from structural topic models \citep{roberts2014structural}. As with any other text-as-data approach, a necessary first step before estimating the topic model is to pre-process the raw text and convert it into a document term matrix \citep[DTM, see for example][]{manning2008introduction}. Common pre-processing procedures include stemming and lowercasing, as well as the removal of numbers, punctuation, stopwords, and infrequent terms. However, topic models and other unsupervised learning techniques can be sensitive to these pre-processing choices \citep[c.f.,][]{denny2018text}. To address this issue, \citet{denny2018text} recommend that researchers compare DTMs under all possible pre-processing regimes. The authors propose \textit{preText scores} as a measure to quantify the extent to which varying pre-processing regimes may yield unusual results compared to a baseline without any pre-processing.

\begin{figure*}[h]
    \centering
    \begin{subfigure}[t]{1\textwidth}
        \centering
        \includegraphics{../fig/pretext2012.pdf}
    \end{subfigure}%
    \\
    \begin{subfigure}[t]{1\textwidth}
        \centering
        \includegraphics{../fig/pretext2016.pdf}
    \end{subfigure}
    \caption{PreText analysis of pre-processing decisions of open-ended responses in the 2012 \& 2016 ANES. Regression coefficients display the effects of each of the six pre-processing choices on the resulting preText score.}\label{fig:pretext}
\end{figure*}

Following the procedure outlined in \citet{denny2018text}, Figure~\ref{fig:pretext} displays the results of a linear model regressing preText scores resulting from all possible pre-processing regimes on each individual step for a random subset of 500 open-ended responses in the 2012 and 2016 ANES. Significant coefficients indicate that the topic model results my be sensitive to the respective pre-processing step. As such, removing stopwords and punctuation, as well as removing infrequent terms (at least in 2016) might be problematic. \citet{denny2018text}, however, emphasize that the most important consideration in choosing pre-processing steps are theoretical. Given that the purpose of the topic model is to extract considerations related to political preferences, there are strong theoretical reasons to remove stopwords and punctuation from open-ended responses as they do not contain any relevant content. Furthermore, I apply lowercasing and stemming of terms to reduce resulting document term matrix to a computationally more manageable size and since these pre-processing steps should not be influential according to the preText analysis.

It is less obvious from a theoretical perspective whether to remove infrequent terms from open-ended responses, although it is preferred in order to make the estimation of the discursive sophistication components computationally efficient. Since the preText analysis for 2016 suggests that this pre-processing step might be influential, I compare discursive sophistication for both alternative regimes below \citep[c.f.,][]{denny2018text}. Before turning to this sensitivity check, however, I consider another crucial modeling choice when working with topic models: determining the total number of topics $k$ to be estimated. For all analyses reported below, the number of topics was selected using the algorithm proposed by \citet{lee2014low} and implemented in the \texttt{stm} package in \texttt{R} \citep{roberts2014stm}.\footnote{I used measures for age, education, party identification, as well as an interaction between education and party identification as covariates for topic prevalence. This variable selection---with the exception of including gender---is equivalent to the procedure model specification described in \citet{roberts2014structural}.} 

\begin{figure}[h]\centering
\includegraphics{../fig/pretext_robustness.pdf}
\caption{Robustness of discursive sophistication measure for different pre-processing choices and topic model specifications.}\label{fig:pretext_robustness}
\end{figure}

Figure~\ref{fig:pretext_robustness} examines whether the proposed measure of discursive sophistication is sensitive to the removal of infrequent terms as well as the chosen number of topics $k$. The x-axis depicts the preferred pre-processing regime including all steps discussed above while the y-axis plots results for alternative specifications. The upper panels compare the preferred specification to discursive sophistication based on a reduced number of topics ($k=20$). The lower panels additionally include infrequent terms instead of removing them.\footnote{Calculating discursive sophistication with large numbers of topics while including infrequent terms is computationally prohibitive.} Results for the 2012 ANES are displayed on the left and results for the 2016 ANES are displayed in panels on the right. Across all four panels, discursive sophistication scores are highly correlated and therefore insensitive to pre-processing choices and varying numbers of topics.

In summary, open-ended responses in the analyses reported below are pre-processed by stemming and lowercasing, as well as the removing numbers, punctuation, stopwords, and infrequent terms (i.e., terms that appear in fewer than 10 responses).\footnote{Prior to applying these pre-processing steps, open-ended responses in the 2012 \& 2016 ANES as well as the 2015 YouGov survey are cleaned by correcting spelling errors using an implementation of the Aspell spell-checking algorithm (\url{www.aspell.net}).} While the results discussed below are based on this preferred specification, the substantive results are robust for alternative pre-processing regimes or varying numbers of topics.



\section*{A First Look at Discursive Sophistication}

Before turning to the validation, I begin by directly comparing discursive sophistication to alternative metrics of political knowledge in the 2012 and 2016 ANES. The most common way to measure political knowledge in surveys is to ask a set of factual questions about political institutions. The ANES surveys include such a basic item battery, inquiring for example about the number of times an individual can be elected President of the United States, or how the current U.S. federal budget deficit compares to the deficit in the 1990s. I combine individual responses on these items to a standard additive measure of \textit{factual knowledge} about politics. Additionally, the in-person samples of the ANES include \textit{interviewer assessments} of each respondent's political sophistication.
% TODO: add citation for use of both knowledge measures

% EXTEND: add relationship with personality measures, examine relationship with extremity, ambivalence, etc.

Figure~\ref{fig:corplot} compares discursive sophistication to the conventional knowledge metrics for both surveys. Each figure presents scatterplots between individual measures (lower triangular), univariate densities (diagonal), and correlation coefficients (upper triangular). The measure of discursive sophistication is positively correlated with both conventional metrics while capturing some additional variation.

\begin{figure*}[h]
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics{../fig/corplot_pres2012.pdf}
        \caption{2012 ANES}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics{../fig/corplot_pres2016.pdf}
        \caption{2016 ANES}
    \end{subfigure}
    \caption{Correlation matrix of conventional political knowledge metrics and discursive sophistication. The plots on the diagonal display univariate densities for each variable. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient. All correlations reported are statistically significant with $p<.05$.}\label{fig:corplot}
\end{figure*}

Interestingly, we observe a stronger correlation between discursive sophistication and interviewer evaluations than between factual knowledge and interviewer evaluations. The open-ended measure therefore appears to capture characteristics that influence subjective assessments of sophistication. The interviewers certainly form their impressions throughout the entire survey, but the complexity of a respondent's verbatim answers seems to be more influential than their performance on the factual knowledge questions.

Overall, while discursive sophistication and the alternative measures are clearly correlated, the relationship between each metric is far from perfect. To provide some intuition whether the variation in discursive sophistication is theoretically meaningful, I present an example of open-ended responses of two individuals in the 2016 ANES who identified as Republicans and scored equally on the factual knowledge score (3 out of 4 correct responses), but varied highly in discursive sophistication. The results are presented in Table~\ref{tab:ex1}.

\begin{table}[ht]\footnotesize\centering
\begin{tabular}{l|p{6.3cm}|p{6.3cm}}
\toprule
	& A: Low Sophistication Response & B: High Sophistication Response \\ \midrule
Clinton (+)		& 																& Politician. \\\hdashline
Clinton (-)		& The fact that she has links to Al-Qaeda. 						& Caught in lies. \\\hdashline
Trump (+)		& 																& Says what he thinks. \\\hdashline
Trump (-)		& He is going to start a civil war. I feel like he is racist. 	& Reality TV star, poor businessman \\\hdashline
Democrats (+)	& 																& Middle class minded. \\\hdashline
Democrats (-)	& 																& Too many handouts. \\\hdashline
Republicans (+)	& 																& Economic growth conscious. \\\hdashline
Republicans (-)	& 																& For the big business. \\\midrule
Disc. Soph. 	& 0.159 														& 0.465 \\\bottomrule

 \end{tabular}
\caption{Example of open-ended responses for low and high scores on discursive sophistication with equal factual knowledge scores (3 out of 4 correct responses). Column A displays the verbatim responses of an individual who scored low on discursive sophistication and column B displays the verbatim responses of an individual who scored high on the open-ended measure. Each row represents one of the likes/dislikes items included in the analysis. Note that the responses in this table were slightly redacted for readability (spelling errors removed, etc.).}\label{tab:ex1}
\end{table}

Each row in the table represents one of the open-ended responses (like/dislike for each candidate/party). Column A displays the responses of an individual who scored low on discursive sophistication and column B displays the responses of a high scoring individual. Cells are empty if a respondent refused to provide a response. Even though both individuals are measured to have equal factual political knowledge, there are systematic differences in their response behavior that can be attributed to their political sophistication. Overall, respondent A provided a less elaborate response, only focused on a narrow range of issues, and only reported attitudes on two items. Irrespective of whether one agrees with the specific statements or whether they are factually accurate (e.g., Clinton's connection to Al-Qaeda), A's response pattern is suggestive of a less sophisticated political belief system and a lower level of motivation to engage in in-depth processing about both parties and candidates. Overall, this initial result suggests that the variation in discursive sophistication captures meaningful differences in response behavior that clearly overlaps with traditional knowledge metrics while displaying some unique variation. The following sections will show that this variation is also politically consequential.



\section*{Discursive Sophistication and Political Competence}

Following the arguments outlined by \citet{lupia2006elitism,lupia2015uninformed}, I proceed to validate the measure of discursive sophistication by directly examining its effects on individual competences to perform political tasks in modern democracies. More specifically, I consider the potential role of political sophistication in promoting (1) engagement and participation in politics, (2) precise positioning of parties and candidates, (3) early preferences about candidates, (4) incorporation of new information, and (5) well-justified political decisions. In the following, each point will be addressed individually using one of the three data sets described above.
% ADD: mention that factual knowledge is used as a benchmark, justify!

\subsection*{Engagement and Participation in Politics}

Political sophistication is often argued to promote individual engagement and participation in politics. Figure~\ref{fig:knoweff} presents the effects of discursive sophistication and factual knowledge in the 2012 and 2016 ANES on four dependent variables commonly related to political sophistication: turnout, non-conventional participation, internal efficacy, and external efficacy. The results for the model predicting turnout is estimated using logistic regression while the effects on the three remaining dependent variables are based on OLS. Each model equation includes both sophistication measures while controlling for gender, education, income, age, race, religiosity, survey mode (face-to-face vs. online), as well as the Wordsum vocabulary score measuring verbal intelligence.

\begin{figure}[h]\centering
\includegraphics{../fig/knoweff_pres.pdf}
\caption{Effects of sophistication on internal efficacy, external efficacy, non-conventional participation, and turnout in the 2012 and 2016 ANES. For each dependent variable, the figure displays the change in expected values after increasing each sophistication measure from -1 to +1 standard deviation from its mean (including 95\% confidence intervals). Model estimates are based on logistic regression (turnout) or OLS (internal efficacy, external efficacy, non-conventional participation). Both sophistication measure are included simultaneously while controlling for gender, education, income, age, race, church attendance, survey mode, and Wordsum vocabulary scores.
%Full model results ar presented in the appendix, Tables \ref{tab:inteff} through \ref{tab:turnout}
}\label{fig:knoweff}
\end{figure}

Each plot in the figure displays the difference in the expected value of the respective dependent variable for a two standard deviation increase in each sophistication measure, while holding all other variables at their means. Overall, discursive sophistication is a stronger predictor of turnout, non-conventional participation, as well as (to a lesser extent) internal and external efficacy. Focusing on the 2012 ANES, the---theoretically expected---positive effect of factual knowledge on participation is statistically indistinguishable from zero when controlling for discursive sophistication. This finding is especially noteworthy since item batteries to measure factual political knowledge are often selected and validated based on their strong relationship with turnout and participation \citep[c.f.,][]{lupia2015uninformed}. Interestingly, we also observe a negative effect of factual knowledge on external efficacy in 2016. Notwithstanding the apparent peculiarities of the 2016 Presidential election, the positive effect of discursive sophistication on external efficacy appears to be more consistent with previous research.
% TODO: add citation for participation claim


\subsection*{Precise Positioning of Parties and Candidates}

Sophistication should not only foster engagement and participation, but also improve the quality of individual decision-making in politics. The most direct way for citizens in representative democracies to influence policy outcomes in their favor is to cast votes for candidates who best represent their interests. In order to accomplish this essential task, citizens need to possess precise information about the candidates' positions on policy issues.

Figure~\ref{fig:hetreg} presents the results of multiple heteroskedastic regressions where the error variance in candidate placements on multiple issues included in both ANES waves (general ideology, government spending, defense spending, health insurance policy, job guarantee) is a modeled as a function of discursive sophistication as well as factual knowledge \citep[see][for a similar procedure]{jacoby2006value}. More formally, each model for a given candidate placement on a specific policy issue takes the following form:
\begin{align}
y &\sim \text{N}(\mu, \sigma) \\
\mu &= X\beta \\
\log(\sigma) &= Z\gamma,
\end{align}
where $y$ is the vector of policy placements of all respondents, $X$ is a matrix of covariates predicting average party/candidate placements $\mu$ (self-placement, education, income, age, religiosity, gender, race, and survey mode), $Z$ denotes the covariates predicting the error variances $\sigma$ (discursive sophistication, factual knowledge, Wordsum score), and $\beta$ and $\gamma$ are the parameters to be estimated.

\begin{figure}[h]\centering
\includegraphics{../fig/hetreg.pdf}
\caption{Error variance reduction in candidate placements on multiple issues in the 2012 and 2016 ANES. The figure displays the difference in estimated error variances after increasing each sophistication measure from -1 to +1 standard deviation from its mean (including 95\% credible intervals). Models are estimated in Stan using non-informative priors.}\label{fig:hetreg}
\end{figure}

The figure displays the estimated reduction in error variances of candidate placements when each sophistication measure is increased by two standard deviations. Larger negative values indicate a stronger reduction in error variances and hence more precise candidate placements. Both factual knowledge and discursive sophistication significantly decrease error variances in policy placements of presidential candidates. Some interesting differences, however, emerge when comparing both waves of the ANES. In the 2012 election, discursive sophistication in open-ended responses was a stronger predictor of precise candidate placements than performance on factual knowledge quizzes across multiple issues. This picture appears to be reversed in the 2016 election, where more elaborate open-ended responses were only weakly predictive of precise candidate placements. This finding may be attributed to idiosyncrasies related to how citizens discuss their preferences for Clinton or Trump as compared to previous candidates, or to higher overall uncertainty about their respective policy positions. Notwithstanding these contextual variations, both factual knowledge and discursive sophistication appear to increase the precision with which individuals place candidates on various policy issues.


\subsection*{Early and Stable Preferences about Candidates}

To the extent that citizens are sufficiently informed about the positions of political candidates well before the election, they should be able to form a vote choice early in a campaign. Respondents in both ANES surveys were asked about their vote intention for the presidential election during the pre-election wave and later reported their actual vote choice in the post-election wave. Figure~\ref{fig:prepost} examines the effect of political sophistication on the probability that individuals keep their vote intention from the pre-election wave to their actual vote choice reported in the post-election wave. Estimates are based on logit models where the dependent variable indicates whether initial vote intentions remained unchanged between both time points.

\begin{figure}[h]\centering
\includegraphics{../fig/prepost_exp.pdf}
\caption{Predicted probability to cast a vote consistent with initial intentions reported in the pre-election wave of the 2012 ANES as a function of political sophistication while holding all other variables constant at their respective means (including 95\% confidence intervals). Estimates are based on logit models controlling for education, income, age, religiosity, gender, race, survey mode, and Wordsum vocabulary scores.}\label{fig:prepost}
\end{figure}

Both, discursive sophistication as well as factual knowledge significantly increase the probability that citizens voted according to their initial intention at the time of the pre-election interview. In both the 2012 and 2016 ANES, the effect of discursive sophistication is larger than the effect of factual knowledge scores. The degree to which individuals provide more elaborate responses discussing their political preferences about both parties and candidates is therefore a better predictor of early and stable voting preferences than the ability to recall facts about political institutions that are relatively unrelated to the task at hand.


\subsection*{Incorporation of New Information}
% TODO: How can I cite Jenn here? Add survey information (questionnaire etc.) in the appendix

Political competence does not necessarily imply that citizens always stay consistent with their initial preferences. After all, individuals should be attentive to their media environments and incorporate potentially relevant new information. Here, I conduct an additional analysis based on the 2015 YouGov survey which included open-ended questions about two political issues that were prominent in the media discourse at the time (gun control and health insurance). Additionally, the study administered a task where respondents read a newspaper article about a fictional infectious disease and were subsequently asked to recall information provided in the article (e.g. regarding symptoms, modes of contraction etc.). I compute an additive index counting the pieces of information that were correctly recalled (\textit{information retrieval}) as a measure of the ability to retrieve information from a news article on a non-partisan issue that is related to public health policies. 

\begin{figure}[h]\centering
\includegraphics{../fig/yg_disease.pdf}
\caption{Expected disease information retrieval in the 2015 YouGov Study as a function of political sophistication (including 95\% confidence intervals). Estimates are based on a linear regression model controlling for education, income, age, religiosity, gender, and race.}\label{fig:yg_disease}
\end{figure}

Figure~\ref{fig:yg_disease} displays the effect of political sophistication on disease information retrieval in the 2015 YouGov study. Estimates are based on a linear regression model controlling for education, income, age, religiosity, gender, and race. As a benchmark for discursive sophistication, I again consider the effect of \textit{factual knowledge} based on a battery of eight items similar to the knowledge questions in the ANES. Again, we observe that both, discursive sophistication as well as factual knowledge increase the amount of information individuals are able to recall from a news article discussing a fictional disease. Similar to the previous results, the effects are stronger for discursive sophistication than for factual knowledge scores. The degree to which citizens are able and motivated to discuss their own political beliefs in a more elaborate manner is not only a stronger predictor of stable and precise candidate assessments but also serves as a better proxy for the ability to incorporate new information.


\subsection*{Well-Justified Political Decisions}

Ultimately, political sophistication should enable citizens to make high-quality decisions based on informed preferences about the issue at hand. \citet{colombo2016justifications} manually coded open-ended responses of Swiss citizens who were asked to explain why they voted in favor or against a given proposition in multiple policy referenda. The author developed a measure of individual \textit{levels of justification}, which combines dimensions of answer content, elaboration, and complexity.

As a last step of the validation effort, I compare discursive sophistication with Colombo's \citeyearpar{colombo2016justifications} original measure. The results are presented in Figure~\ref{fig:swiss_ggridges}. Since the Swiss post-referendum surveys were conducted in three different languages (German, French, and Italian), I computed the measure of discursive sophistication for each group of respondents. The figure displays the distribution of discursive sophistication for each level of justification captured by \citet{colombo2016justifications} as well as the correlation coefficients for both respective variables. Discursive sophistication is systematically higher among respondents with the highest level of manually coded justification and both measures are positively correlated across all three language groups ($r=0.29, 0.25$, and $0.35$, respectively). The measure proposed in this paper therefore shows a high degree of correspondence with manual coding of individual levels of justification across three languages.


\begin{figure}[h]\centering
\includegraphics[scale=1]{../fig/swiss_ggridges.pdf}
\caption{Discursive sophistication and manually coded level of justification \citep{colombo2016justifications} in Swiss post-referendum surveys. The plot compares kernel densities of discursive sophistication for each manually coded level of justification.}\label{fig:swiss_ggridges}
\end{figure}

Overall, the results presented thus far indicate that discursive sophistication shares common characteristics with factual political knowledge measures. Compared to conventional metrics, the proposed measure performs as least as well as a predictor of essential competences that allow citizens to engage successfully in politics. In fact, discursive sophistication is a stronger predictor of certain outcomes (such as political participation, or preference stability) than conventional knowledge scores. In the following, I turn to an application to examine how discursive sophistication can help refine important previous insights from the literature on political knowledge.

%\section*{Robustness Checks: Personality and Open-Ended Responses}
% THIS IS FOR POST APSA! -> check whether discursive sophistication or polknow is more influenced by personality characteristics that should be unrelated with sophistication...


\section*{Application: The Gender Gap in Political Knowledge}
% APPENDIX: add additional analyses controlling for wordsum score, substantive results are unchanged

%One example for such potential misclassifications is the issue of gender differences in sophistication. On the basis of conventional factual knowledge scores, women frequently appear to be less informed about politics than men \citep{verba1997knowing,wolak2011roots}. However, some scholars suggested that these differences might be rooted in the conceptual and methodological issues related to the measurement approach. For example, \citet{mondak2004knowledge} argue that at least part of the gender gap in sophistication can be attributed to the fact that women are less likely to guess than men when facing a factual knowledge question for which they do not know an immediate answer. Others suggest that the gap can be attenuated by focusing on gender-relevant political knowledge \citep[e.g.,][]{dolan2011women} or by providing policy-specific information \citep[e.g.,][]{jerit2017revisiting}.


A common finding in research on political sophistication is the fact that women appear to be less knowledgeable about politics than men. For example, \citet{verba1997knowing} report that women score lower on political information, interest, and efficacy, which decreases their respective levels of political participation. Since gender differences in political information and interest can only partly be explained by resource-related factors such as individual levels of education, the authors diagnose a ``genuine difference in the taste for politics'' between men and women, which they suspect to be driven largely by socialization \citep[see also][]{wolak2011roots}. Indeed, \citet[117]{dow2009gender} describes the systematic gender differences in knowledge ``[o]ne of the most robust findings in the study of political behavior.''

One explanation for the finding that disparities in resources (e.g., education) cannot fully account for gender differences is the fact that men and women benefit differently from the factors that increase political information \citep{dow2009gender}. As such, the gap is not only due to varying resource levels, but also due to differential gains from the resource itself. More broadly, this finding suggests that men and women consume political information through different channels \citep[see also][]{pietryka2013analysis}. Nevertheless, recent research showed that the gender gap can be substantially decreased given exposure to sufficient information \citep[e.g.][]{jerit2017revisiting} or through deliberation \citep{fraile2014does}.

Other scholars focused more closely on issues related to the measurement of political knowledge in order to explain the apparent gender gap. For example, \citet{mondak2004knowledge} suggest that women are more likely to report that they do not know the answer to a knowledge item if they are not completely certain, whereas men are more inclined to guess. Correcting for the systematic differences in the propensity to guess mitigates the gender gap in knowledge but does not eliminate it completely \citep[see also][]{lizotte2009explaining}. Based on their empirical evidence, \citet{mondak2004knowledge} elaborated on best practices regarding the measurement of political knowledge (e.g., using closed rather than open-ended knowledge items and discouraging `Don't Know' responses). Other related aspects of the survey context have also been shown to affect gender differences in political knowledge. For example, \citet{mcglone2006stereotype} present evidence that the gender gap is exacerbated in an environment that induces stereotype threat, for example if women are aware of the fact that the study focuses on gender differences or if they are interviewed by a male interviewer. However, gender differences are not only induced by \textit{how} researchers ask their questions, but also by the question \textit{content} itself. For example, \citet{dolan2011women} argues that the gap can be closed by focusing on gender-relevant political knowledge items such as information about women's representation in the federal government \citep[see also][]{graber2001processing}. Similarly, \citet{stolle2010women} report that the gender gap disappears when people are asked about more practical issues related to the government (e.g., benefits and services).

Overall, the gender gap has been shown to be influenced by how we ask for political information in surveys, as well as the kind of knowledge that is required for a correct response. Indeed, a comprehensive cross-national analysis of election studies in 47 countries between 1996 and 2011 suggests that question format and content account for large portions of the variance of gender disparities in political knowledge \citep{fortin2016cross}.


\subsection*{Descriptive Results}

How do men and women compare on the different metrics of political sophistication in the surveys analyzed in the present study? Figure~\ref{fig:meandiff} displays the average levels of discursive sophistication as well as alternative metrics comparing both genders. While we observe a sizable gender gap for factual knowledge and interviewer assessments in both ANES surveys, this difference disappears for discursive sophistication. These results are replicated when looking at the 2015 YouGov survey. As before, we observe a significant gender gap in factual knowledge, which disappears using the discursive measure. Interestingly, there is also no apparent gender gap in disease information retrieval. If anything, women are able to recall slightly more accurate information about the infectious disease described in the news article. This result is consistent with recent research by \citet{jerit2017revisiting}, which suggests that knowledge gaps between men and women disappear upon receiving sufficient information. It is also worth noting that we do not find significant gender differences across all three language in the Swiss referendum surveys. Even more importantly, this lack of a gender gap is consistent with the results for Colombo's \citeyearpar{colombo2016justifications} manually coded measure of individual levels of justification in open-ended responses.

\begin{figure}[h]\centering
\includegraphics{../fig/meandiff.pdf}
\caption{The gender gap in political sophistication. The figures display mean levels of sophistication for each measure comparing men and women (including 95\% confidence intervals). Gender differences in factual knowledge and interviewer evaluations are statistically significant with $p<.05$.}\label{fig:meandiff}
\end{figure}


\subsection*{Controlling for Alternative Explanations}

Prior scholars suggested that at least part of the gender gap can be attributed to real differences in resources relevant to political information (e.g., education). Accordingly, we need to control for common determinants of political knowledge across all available measures to provide a more comprehensive examination of potential gender differences. Previous studies consistently showed that political knowledge is positively related to high media exposure, frequent political discussions, education, and income. Furthermore, I include age, race, religiosity, and survey mode (face-to-face vs. online) as additional control variables. Figure~\ref{fig:determinants} displays the coefficients of regression models with each knowledge/sophistication measure as the dependent variable.

\begin{figure}[h]\centering
\includegraphics{../fig/determinants.pdf}
\caption{Common determinants of political sophistication. Estimates are OLS regression coefficients with 95\% confidence intervals. Dependent variables are discursive sophistication as well as conventional metrics of political knowledge.
%Full model results are presented in the appendix, Table~\ref{tab:determinants}
}\label{fig:determinants}
\end{figure}
% NOTE: rescale knowledge variables to unit variance? the effects would be better to compare...

After controlling for common determinants in the 2012 and 2016 ANES, discursive sophistication again reveals no significant differences between men and women. On the other hand, we still observe the gender gap using the remaining political knowledge metrics across all surveys considered here. As such, women might not score as highly on political quizzes (partly because of the question content or because women are less likely to guess rather than express lack of knowledge), but they do not differ substantially in complexity and sophistication when they describe their political preferences.

The patterns for the remaining determinants are quite similar across different dependent variables. Knowledge and sophistication is significantly higher among respondents who are more exposed to political news media, discuss politics frequently, are more educated, and have higher income. An interesting deviation, however, is the effect of survey mode. For factual knowledge questions, we observe that respondents in online surveys score significantly higher than individuals in face-to-face interviews. This difference could be explained by the fact that individuals are able to look up responses to factual knowledge questions while taking an online survey \citep[see also][]{clifford2016cheating}. For discursive sophistication, on the other hand, we see that individuals appear to score lower on sophistication in online surveys. Respondents in online surveys therefore seem less willing to elaborate on their attitudes. Overall, the fact that the determinants of political sophistication are very consistent across models lends additional validity to the open-ended measure.

As before, this result is replicated when examining data from the 2015 YouGov survey: men do not perform better than women on discursive sophistication in a multivariate setting. The gender gap in factual political knowledge, however, persists and is substantively as well as statistically significant. The remaining determinants of sophistication/knowledge are similar across measures (except for family income).

% Interestingly, the observed pattern of effects on discursive sophistication is strikingly similar to the effects on information retrieval about the fictional disease. This result reinforces the conclusion that discursive sophistication and disease information retrieval in the YouGov study share common characteristics in the sense that they capture how individuals recall considerations that are relevant to their own attitudes rather than inquiring about facts related to political institutions and elites that are extraneous to the issues at hand.

To summarize, we only observe a significant gender gap when looking at conventional measures as well as interviewer assessments---a result that previous research (at least partly) attributed to the content (i.e., focusing on issues that are less relevant to women) and format (i.e., stereotype-threat and guessing) of the question batteries as well as gender biases in perceived knowledge.\footnote{Interestingly, the gender gap in interviewer assessments in the 2012 ANES is about half as large (albeit still statistically significant) among female interviewers than among male interviewers.} Across all alternative measures---including discursive sophistication, manually coded levels of justification, or information retrieval in a survey task---this difference between men and women disappears.


\subsection*{Explaining the (Lack of the) Gender Gap}

If it is the case that women are able to close the gender gap in discursive sophistication because they are able to focus on different considerations that are salient to them when discussing their political preferences, then we should observe systematic variation in the issues men and women discuss in open-ended responses. Based on the structural topic model used to compute discursive sophistication, Figure~\ref{fig:stm_gender} displays a subset of topics that showed the largest absolute gender difference in topic prevalence in the 2012 and 2016 ANES.

\begin{figure}[h]\centering
\includegraphics[width=\textwidth]{../fig/stm_gender.pdf}
\caption{Gender differences in topic proportions based on the structural topic model used to compute discursive sophistication (including 95\% confidence intervals). Coefficients indicate the difference in predicted topic prevalence among men and women; positive values indicate higher prevalence among women. Labels are based on the five highest probability terms related to the topic.
%Full model results are presented in the appendix, Table~\ref{tab:determinants}
}\label{fig:stm_gender}
\end{figure}

Positive coefficients indicate that women are more likely than men to mention a given topic, and vice versa. As such, the top five topics are more prevalent among men and the bottom five have a higher probability to be mentioned by women. Each coefficient is labeled with the five highest probability terms related to the topic to illustrate its content. Across both ANES studies, women were less likely than men to discuss foreign affairs, economic growth, federal government spending, or the Supreme Court. Instead, they focused on issues related to women's rights, equality, or health care. The considerations taken into account by women when discussing their political preferences are therefore clearly different from men's and---crucially---the issues raised by men happen to be more aligned with what political scientists often deem as necessary information (i.e., pertaining to the economy, institutions, elites, etc.). Yet, from a normative perspective, there is no reason to assume that one set of issues should be more important for citizens when forming their political preferences and making competent voting decisions.

% REVISE: Make a reference to Jenn's study, which found that gender differences disappear if information is provided to respondents

% IDEA: out-party sophistication vs. in-party sophistication?
% I could split up the measure by in-party vs. out-party and examine
% the difference as an indicator of political tolerance etc.
% maybe there is an item that examines whether people would revise their vote choice etc. after the election and I could compare traditional knowledge vs. discursive sophistication.


\section*{Conclusion}
% lot's of potential extensions, think about standardizing the measure to make it more comparable across contexts
% Zaller argues that it captures what actually got into people's minds... that's a perfect argument for open-ended responses! check also the druckman paper.
% Make a connection to political competence, we shouldn't care as much about political knowledge that is favored by elites, but rather examine whether individuals are able to discuss their political views in a coherent way. Seen that way, one could make an argument that political competence captures the extent to which individuals are able to incorporate new information.
% What is a competent citizen? One who has good reasons for his or her attitudes... we can measure that when examining how repondents talk about their political beliefs.

Political scientists should worry less about pure levels of \textit{information}, but rather focus on the necessary conditions for individuals to make \textit{competent} decisions. Competence in the context of political decision-making and voting requires citizens to hold informed attitudes about their representatives. Factual knowledge about political institutions might be a useful proxy for competence in certain scenarios. However, it cannot address directly whether individuals hold well-considered opinions about political actors they try to hold accountable. In comparison, the measure of discursive sophistication proposed here is agnostic about the specific contents of individual beliefs, but directly captures the complexity of individual attitude expressions.

The findings presented in this paper show that conventional knowledge indices and the discursive measure share a substantial amount of variance. However, they are far from being identical and capture different aspects of sophistication. Most importantly, using the discursive measure, any evidence for the gender gap commonly reported using factual knowledge scales disappears. Women might know fewer facts about political institutions, but they do not differ substantively in the complexity of their expressed political beliefs. The fact that women perform just as well as men on discursive sophistication across various surveys can be attributed to the fact that they focus on different considerations when evaluating political parties and candidates. This issue has long been recognized in the literature \citep[e.g.,][]{graber2001processing,dolan2011women}, but it cannot be properly addressed while relying exclusively on off-the-shelf political knowledge batteries. Directly examining how individuals justify their political preferences, in turn, provides a solution that does not rely on strong assumptions about what citizens ought to know.

%\clearpage
\singlespacing
\bibliographystyle{/data/Dropbox/Uni/Lit/apsr2006}
\bibliography{/data/Dropbox/Uni/Lit/Literature}

\clearpage
\section*{Appendix A: Open-ended Responses in the 2012 \& 2016 ANES}
\renewcommand\thefigure{A.\arabic{figure}}
\renewcommand\thetable{A.\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}

\begin{figure}[h]\centering
\includegraphics{../fig/wc.pdf}
\caption{Histogram of total word count in the collection of open-ended responses for each individual. The dashed red line indicates the average response length. Most respondents provide brief statements when they describe their attitudes towards political parties and candidates. The mean response length to all 8 questions is about 75 words, so an average response to a single question consisted of less than 10 words, omitting respondents who did not provide any information.}\label{fig:wc}
\end{figure}

\begin{figure}[h]\centering
\includegraphics[width=\textwidth]{../fig/stm_prop.pdf}
\caption{Estimated topic proportions based on the structural topic model. The number of topics $k$ for the structural topic model is selected using the algorithm proposed by \citet{lee2014low}. I use measures for age, gender, education, party identification, as well as an interaction between education and party identification as covariates for individual topic prevalence, which is similar to the model specification described in \citet{roberts2014structural}. The results in the paper are robust for alternative specifications of $k$ (e.g., setting the total number of topics to 20.}\label{fig:stm_prop}
\end{figure}

\begin{figure}[h]\centering
\includegraphics{../fig/corplot_components.pdf}
\caption{Correlation matrix of individual components of discursive sophistication. The plots on the diagonal display univariate densities for each component. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient. The spike at 0 for opinionation is due to the fact that some respondents only answered a single open-ended question.}\label{fig:components}
\end{figure}



% COMBINE: combine histograms etc. for different datasets in a single plot...
% ADD: Specific information about the individual topic models etc.


\clearpage
\section*{Appendix B: Open-ended Responses in YouGov Data}
\renewcommand\thefigure{B.\arabic{figure}}
\renewcommand\thetable{B.\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}

\begin{figure}[h]\centering
\includegraphics{../fig/yg_wc.pdf}
\caption{Histogram of total word count in the collection of open-ended responses for each individual. The dashed red line indicates the average response length. Most respondents provide brief statements when they describe their attitudes towards political parties and candidates. The mean response length to all 4 questions is about 73 words, so an average response to a single question consisted of approximately 18 words, omitting respondents who did not provide any information.}\label{fig:yg_wc}
\end{figure}


\begin{figure}[h]\centering
\includegraphics{../fig/yg_corplot_components.pdf}
\caption{Correlation matrix of individual components of discursive sophistication. The plots on the diagonal display univariate densities for each component. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient. The number of topics $k$ for the structural topic model is set to 20. I use measures for age, education, party identification, as well as an interaction between education and party identification as covariates for individual topic prevalence, which is equivalent to the model specification described in \citet{roberts2014structural}. The results in the paper are robust for alternative specifications of $k$ (e.g., selecting $k$ using the algorithm proposed by \citet{lee2014low} results in total number of 73 topics). The spike at 0 for opinionation is due to the fact that some respondents only answered a single open-ended question.}\label{fig:yg_components}
\end{figure}



\clearpage
\section*{Appendix C: Open-ended Responses in Swiss Referendum Data}
\renewcommand\thefigure{C.\arabic{figure}}
\renewcommand\thetable{C.\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}

\begin{figure}[h]\centering
\includegraphics{../fig/swiss_wc.pdf}
\caption{Histogram of total word count in the collection of open-ended responses for each individual. The dashed red line indicates the average response length. Most respondents provide brief statements when they describe their attitudes towards political parties and candidates. The mean response length to both questions is about 11 words, so an average response to a single question consisted of approximately 5 words, omitting respondents who did not provide any information.}\label{fig:swiss_wc}
\end{figure}

\begin{figure}[h]\centering
\includegraphics{../fig/swiss_corplot_german_components.pdf}
\caption{Correlation matrix of individual components of discursive sophistication (German respondents). The plots on the diagonal display univariate densities for each component. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient. The number of topics $k$ for the structural topic model is set to 30. I use measures for age, education, party identification, as well as an interaction between education and party identification as covariates for individual topic prevalence, which is equivalent to the model specification described in \citet{roberts2014structural}. The results in the paper are robust for alternative specifications of $k$ (e.g., selecting $k$ using the algorithm proposed by \citet{lee2014low} results in total number of 45 topics). The spike at 0 for opinionation is due to the fact that a large portion of respondents only answered a single open-ended question.}\label{fig:swiss_german_components}
\end{figure}


\begin{figure}[h]\centering
\includegraphics{../fig/swiss_corplot_french_components.pdf}
\caption{Correlation matrix of individual components of discursive sophistication (French respondents). The plots on the diagonal display univariate densities for each component. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient. The number of topics $k$ for the structural topic model is set to 30. I use measures for age, education, party identification, as well as an interaction between education and party identification as covariates for individual topic prevalence, which is equivalent to the model specification described in \citet{roberts2014structural}. The results in the paper are robust for alternative specifications of $k$ (e.g., selecting $k$ using the algorithm proposed by \citet{lee2014low} results in total number of 43 topics). The spike at 0 for opinionation is due to the fact that a large portion of respondents only answered a single open-ended question.}\label{fig:swiss_french_components}
\end{figure}


\begin{figure}[h]\centering
\includegraphics{../fig/swiss_corplot_italian_components.pdf}
\caption{Correlation matrix of individual components of discursive sophistication (Italian respondents). The plots on the diagonal display univariate densities for each component. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient. The number of topics $k$ for the structural topic model is set to 30. I use measures for age, education, party identification, as well as an interaction between education and party identification as covariates for individual topic prevalence, which is equivalent to the model specification described in \citet{roberts2014structural}. The results in the paper are robust for alternative specifications of $k$ (e.g., selecting $k$ using the algorithm proposed by \citet{lee2014low} results in total number of 47 topics). The spike at 0 for opinionation is due to the fact that a large portion of respondents only answered a single open-ended question.}\label{fig:swiss_italian_components}
\end{figure}


\clearpage
\section*{Appendix D: YouGov Correlation Matrix}
\renewcommand\thefigure{D.\arabic{figure}}
\renewcommand\thetable{D.\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}

Figure~\ref{fig:yg_corplot} examines the distribution of each measure of political knowledge as well as their respective correlations in the YouGov data. Again, we observe that discursive sophistication and factual political knowledge are positively correlated, which indicates that discursive sophistication overlaps with traditional knowledge metrics while capturing unique variation in individual response behavior. Interestingly, there appears to be a stronger relationship between discursive sophistication and disease information than between factual political knowledge and disease information.

\begin{figure}[h]\centering
\includegraphics{../fig/yg_corplot.pdf}
\caption{YouGov data -- Correlation matrix of discursive sophistication, a conventional political knowledge metric, and disease information retrieval. The plots on the diagonal display univariate densities for each variable. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient. All correlations reported are statistically significant with $p<.05$.}\label{fig:yg_corplot}
\end{figure}

Recall that the disease information score can be interpreted as an indicator of the ability to retrieve specific information provided in a news article about a public health issue. It could be argued that discursive sophistication is more similar to the disease information score in that it captures the extent to which participants were able to recall political information that is relevant to their own attitudes. Conventional knowledge scores, on the other hand, inquire about specific that are not necessarily relevant to derive well-informed attitudes about political issues.


%\clearpage
%\section*{Appendix E: Tables of Model Estimates}
%\renewcommand\thefigure{E.\arabic{figure}}
%\renewcommand\thetable{E.\arabic{table}}
%\setcounter{figure}{0}
%\setcounter{table}{0}
%
%\input{../tab/inteff}
%\input{../tab/exteff}
%\input{../tab/nonconv}
%\input{../tab/turnout}
%\input{../tab/determinants}
%\input{../tab/closing}
%\input{../tab/yg_determinants}

\end{document}