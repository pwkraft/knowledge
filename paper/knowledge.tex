\documentclass[12pt]{article}
\usepackage[margin = 1in]{geometry}
\usepackage[USenglish]{babel}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{lscape}
\usepackage{dcolumn}
\usepackage{xcolor}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{arydshln}
\usepackage{dcolumn}
\usepackage[colorlinks=true,citecolor=red!50!black,urlcolor=blue!50!black,linkcolor=red!50!black]{hyperref}

\author{Patrick W. Kraft\footnote{Ph.D. Candidate, Stony Brook University, \href{mailto:patrick.kraft@stonybrook.edu}{patrick.kraft@stonybrook.edu}.
}}
\date{today}

\title{Looking for Answers\\
\large{Measuring Political Sophistication in Open-Ended Responses}\footnote{Previous versions of this manuscript have been presented at Polmeth 2016, MPSA 2017, EPSA 2017, and ISPP 2017.
The manuscript and code are available on GitHub: \url{https://github.com/pwkraft/knowledge}.
% I thank Jennifer Jerit, Jason Barabas (?), Yanna Krupnikov, Stanley Feldman, C{'e}line Colombo, Fabrizio Gilardi
}
}
\date{\today}

% sans serif font
\renewcommand{\familydefault}{\sfdefault}


\begin{document}
\maketitle
\doublespacing
\thispagestyle{empty}

\begin{center}
-- WORK IN PROGRESS -- \\
PLEASE DO NOT CITE OR REDISTRIBUTE WITHOUT PERMISSION
\end{center} 

\hfill
\begin{abstract}\singlespacing
This paper proposes a simple but powerful framework to assess political sophistication in verbatim responses to open-ended survey items. The measure aims to capture the complexity of individual attitude expressions by examining their relative length, topic diversity, and opinionation. I validate the approach by comparing the measure to conventional political knowledge metrics in multiple studies using different batteries of open-ended items. The paper proceeds to illustrate how text-based sophistication helps refine important previous insights from the literature, for example regarding the oft-cited gender gap in political knowledge.
% This is just a placholder abstract for now, needs some serious revisions.
% QUESTION: measure can be based on different sets of items

%\vspace{\baselineskip}
%\noindent \textbf{Keywords:} political sophistication, gender gap, measurement, open-ended responses, text analysis \\

\end{abstract}
\hfill
\newpage\setcounter{page}{1}


% REVISE: mention data sources earlier in the manuscript?
% REPLACE: "recall" instead of "factual" knowledge questions

%\vspace{-2em}
\begin{quote}\singlespacing
\textit{``Trump owes his victory to the uninformed. But it's not just Trump. Political scientists have been studying what voters know and how they think for well over 65 years. The results are frightening.''}
\end{quote}

Two days after the 2016 US Presidential election, Jason Brennan provided this--- rather grim---view of the electorate in an article titled ``Trump Won Because Voters Are Ignorant, Literally'' published on \textit{ForeignPolicy.com}. While the election of Donald J. Trump is certainly exceptional in various ways, the assessment of alarmingly high levels of voter ignorance can hardly be seen as a novel phenomenon. Quite contrary, it has been one of the major reoccurring themes in public opinion research. Not too long ago, for example, \citet{bartels2005homer} attributed public support for the Bush administration's 2001 and 2003 tax cuts to a substantial lack of political information among voters \citep[but see][]{lupia2007were,bartels2007homer}. Similarly, Delli Carpini and Keeter's \citeyearpar{carpini1996americans} seminal book on political knowledge warned that widespread ignorance might jeopardize equal representation of citizens. Early influential scholars such as \citet{converse1964nature} also emphasized that large parts of the public lack a sufficient understanding of abstract ideological concepts and do not hold stable issue positions. Indeed, the finding that citizens appear to know too little about politics seems to go as far back in history as the systematic study of political knowledge itself.

% The following para should be revised...
Yet, not everyone agrees with this pessimistic assessment. Instead, there has been a lively debate about how to accurately assess political knowledge in the first place \citep[e.g.][]{mondak2000reconsidering,mondak2001asked,sturgis2008experiment,debell2013harder,pietryka2013analysis}. Most analyses rely on standard item batteries that assess individuals' factual knowledge about political institutions and officeholders \citep[e.g.,][]{carpini1996americans}. However, recent research points to important distinctions in types of political knowledge that have previously been disregarded \citep{barabas2014question}. Furthermore, scholars argue that recall-based measures of political knowledge do not necessarily capture how people structure their attitudes and beliefs \citep[e.g.][]{luskin1987measuring} and may not be theoretically relevant for political participation \citep{lupia2006elitism}.

The last point raises a fundamental question about the type of knowledge that is actually necessary for outcomes we view as desirable \citep[see also][]{lupia2015uninformed}: Do citizens really need to know specific details about US political institutions in order to successfully engage in politics? For example, precise knowledge of the official term lengths of U.S. Senators can hardly be viewed as necessary to cast an informed vote between two candidates running for President. This is especially the case since voters can rely on heuristics \citep{lupia1994shortcuts} or procedural knowledge \citep{prior2008money} when forming political preferences. Factual knowledge as measured in many public opinion surveys is therefore not an ideal indicator for citizens' competence to engage in politics.

% More direct/active language in this para:
The present paper proposes an alternative measure of political sophistication that aims to address this disconnect. Normative democratic theory suggests that voters should hold informed opinions about available candidates and relevant issues before casting a vote. Rather than relying on factual knowledge that is potentially unrelated to the task at hand, I examine how respondents discuss their political preferences and beliefs in their own words. For a given set of verbatim responses, the measure assesses political sophistication based on relative response lengths, diversity in topics raised by individuals, as well as their level of opinionation. The goal is to assess whether political attitudes relevant to perform a specific task are expressed in a more elaborate manner---a question that is not directly discernible when examining off-the-shelf factual knowledge items. %The text-based measure is therefore conceptually closer to the degree of structure and constraint in political belief systems \citep[see for example][]{tetlock1983cognitive,luskin1987measuring}. 

% TODO: revise this section, predictor part comes out of nowhere
The proposed measure is validated across multiple data sets by comparing it to conventional factual knowledge scores as predictors of competences relevant to perform political tasks. While the measures share a considerable amount of variance, they are far from equivalent. Indeed, text-based sophistication is a stronger predictor of internal efficacy, political engagement, and turnout than most traditional measures. After validating the measurement approach, the paper illustrates how text-based sophistication can help refine previous insights in the literature by re-examining an oft-cited finding in empirical research---the gender gap in political knowledge. Contrary to previous research, I find no evidence for such a gap based on open-ended responses. While women might score lower than men on factual knowledge about political institutions and elites, there are no differences in the complexity of expressed political attitudes. More generally, the results suggest that developing valid measures of political sophistication based on open-ended responses can provide new opportunities to examine political knowledge across time and contexts. 


\section*{Factual Knowledge and Political Competence}
%\section*{Recalling Facts Does Not Imply (Political) Competence}
% 1: gender gap is a commom phenomenon in the literature
% 2: potential explanations based on measurement
% 3: broader issue: do we need political facts or structure of belief systems? competence?
% ADD: section on the role of competences etc.
% REVISE: all tests of political knowlege should follow based on the required competences

% A lot of political science research focuses on political knowledge, but that's not really what we should care about. Lupia's competence argument...

A common theme in public opinion research revolves around the question whether citizens fulfill the requirements necessary to hold their elected officials accountable. Pioneered by \citet{carpini1996americans} and others, much of this inquiry has focused on individual levels of factual knowledge about political institutions and officeholders \citep[see also][]{carpini1993measuring}. For example, \citet[21]{zaller1992nature} argued that testing factual information about politics provides the best available measure of political awareness, since it ``more directly than any of the alternative measures, capture[s] what has actually gotten into peopleâ€™s minds.'' Studies in this area frequently attest that large parts of the public do not meet the standards determined by researchers. Quite contrary, the citizenry appears mostly disengaged, uninterested, and above all ill-informed about politics, which can ultimately result in unequal representation in the political system \citep[e.g.,][]{althaus1998information,kuklinski2000misinformation,gilens2001political}.

However, this is not the only recurring theme in the literature related to citizens' level of information. More specifically, there are frequent debates about the proper measurement of political knowledge in the first place. For example, \citet{krosnick2008problems} emphasized problems related to the coding rules of common recall items included in the American National Election Study, which fail to properly capture partial knowledge \citep[see also][]{gibson2009knowing,debell2013harder}. \citet{mondak2000reconsidering} raised additional concerns by showing that individual performance on political knowledge items is influenced by differential probabilities to engage in guessing \citep[see also][]{mondak2001developing,mondak2001asked,miller2008experimenting}. While the question of measurement is certainly an important debate with noteworthy recent contributions \citep[e.g.,][]{pietryka2013analysis}, there is a more fundamental theoretical issue related to the measurement of political knowledge that is frequently overlooked: \textit{What do citizens need to know in order to participate effectively in the democratic process?}

% THIS STILL NEEDS SOME HEAVY REVISIONS, especially the last part.
The most important task for citizens in a modern democracy is to hold their elected officials accountable and vote for candidates who represent their interests. Arguably, survey items measuring political knowledge should therefore cover information that is necessary and/or sufficient to perform this essential task. Yet, as \citet[219]{lupia2006elitism} explains, ``Most political knowledge questions are not derived from a replicable or transparent logic about how their answers bear on a voter's ability to make decisions of a particular quality.'' As such, information requested in conventional survey items have no clear relevance to political participation. \citet{lupia2006elitism} argues that instead of focusing on potentially irrelevant factual knowledge, researchers should concentrate on heuristics that directly help citizens to make competent political decisions or focus only on knowledge relevant to a specific task \citep[see also][]{lupia1994shortcuts,lupia2015uninformed}. After all, there is no need for individuals to know all available facts, but only to possess the skills and resources to be able to \textit{find} the information required in a specific context \citep{prior2008money}.



Furthermore, conventional items differ with regard to the dimension of political knowledge they measure \citep{barabas2014question} and ignore important aspects such as visual cues \citep{prior2014visual}.

Druckman argument. Issue of representation, why common indicators of political knowledge are insufficient. What are the alternatives? Think of attitude formation!

Lupia argument, identify a task and the necessary competences. Criteria to select knowledge questions are often random, not guided by theory about necessary competences. Think about what people need to do, then think about how to assess whether they can do that.

\section*{Opinion Formation and Attitude Expression}
%\section*{What do People Have to Say About the Issues?}
% ADD: issue of item choice, etc.
% ADD chapter reviewing approaches that focus on linguistic complexity, dictionaries capturing integrative complexity etc..


% Rather than using off-the-shelf item batteries to measure general knowledge, we can simply ask respondents to discuss their preferences in beliefs in a specific field of substantive interest and then go from there.

Rather than trying to develop a new item battery that addresses some of these issues, I propose an alternative approach. Instead of testing respondents on a specific set of predetermined facts, we can make inferences about political sophistication by analyzing how they discuss their attitudes and beliefs in their own words.

One of the advantages of measuring sophistication based on open-ended responses is that it can be applied in various settings that potentially focus on different types of political attitudes. Indeed, the logic of the text-based sophistication measure is not restricted to the type of open-ended items included in the 2012 ANES. From a theoretical perspective, the same arguments regarding the structure of individual belief systems holds when examining other types of open-ended responses, for example when respondents discuss their attitudes toward specific policy issues.

%\section*{Factual Problems with Political Knowledge}

\section*{Measuring Text-Based Sophistication}
% 1: if we care about the structure of belief systems, how would they respond to open-ended items?
% 2: how are open-ended responses administered, potential issues
% describe dataset and open-ended responses
% describe measure for each dimension as well as composite measure of sophistication

% ADD: differentiate from manual coding of integrative complexity (labor intensive) and dictionary-based methods (focus on linguistic characteristics, which could easily conflate general eloquence)

Let's return to our initial discussion of the theoretical concept of interest -- political sophistication. As described above, \citet{converse1964nature} focused on the level of constraint in political beliefs rather than isolated pieces of factual information. Similarly, \citet{tetlock1983cognitive} used the term \textsl{integrative complexity} to describe the degree to which considerations related to an issue are interconnected. These studies do not conceptualize sophistication based on the content (or accuracy) of related considerations but rather on its \textsl{structure}. \citet{luskin1987measuring} also defined political sophistication based on the structure of individual belief systems, arguing that belief systems can vary on three separate dimensions: (1) their \textsl{size} -- i.e. the number of cognitions, (2) their \textsl{range} -- i.e. the dispersion of cognition over categories, and (3) their \textsl{constraint} -- i.e. the extent to which cognitions are interconnected in a meaningful way. Political sophistication, in turn, is seen as the conjunction of these dimensions: ``A person is politically sophisticated to the extent to which his or her [political belief system] is large, wide-ranging, and highly constrained.'' \citep[860]{luskin1987measuring}.

How would such a highly sophisticated person discuss his or her political views compared with a less politically sophisticated individual? Consider for example a survey where respondents are asked to describe their attitudes toward specific policies or candidates running for office in their own words. In such a scenario, the structure of individual political belief systems (i.e., size, range, and constraint) should be reflected in their verbatim responses to a set of open-ended items. In the following, I discuss three different attributes of open-ended survey responses that should be indicative of individual political sophistication as described by \citet{luskin1987measuring} and others.

First of all, sophisticated individuals should be able to elaborate more on their political attitudes. If people possess a large, wide-ranging, and constrained belief system, they should be able to recall a large number of considerations related to political actors or issues. Verbatim responses of sophisticates can therefore be expected to have a greater overall \textbf{length}, which is measured as the logged word count for each individual over all prompts:
\begin{equation}
\text{length}_i = \dfrac{\log\left(\sum_{j=1}^J n_{ij}\right)}{\max\left[\log\left(\sum_{j=1}^J n_{ij}\right)\right]},
\end{equation}
where $n_{ij}$ is the number of words in the response of individual $i$ in response to question $j$. $J$ denotes the set of all open-ended probes. I use the logged count to normalize the distribution of responses and divide it by the maximal response length in the data such that the resulting measure ranges from 0 to 1.

However, sophisticated individuals should not only be able to talk about their attitudes at greater lengths. It is also important to consider the content of their respective answers. If a respondents holds more diverse cognitions towards political actors or policies, we should observe a wider range of topics addressed in their responses rather than a focus on single issues. As such, verbatim responses of political sophisticates should display a greater degree of \textbf{topic diversity}, which is conceptualized as the relative mean absolute difference in topic proportions:\footnote{Individual topic proportions are extracted from a structural topic model estimated using the \texttt{stm} package in R \citep{roberts2014structural}. The number of topics was selected using the algorithm of \citet{lee2014low} and the model was estimated via spectral initialization to address the issue of multi-modality \citep[see][for details]{roberts2014stm}. I use measures for age, education, party identification, as well as an interaction between education and party identification as covariates for topic prevalence. This variable selection is equivalent to the procedure model specification described in \citet{roberts2014structural}. %I estimated a total number of 72 topics. The results reported hereafter are robust for model specifications with fewer numbers of topics.
}
\begin{equation}
\text{topic diversity}_i = 1-\dfrac{\sum_{k_1=1}^K\sum_{k_2=1}^K |\theta_{ik_1} - \theta_{ik_2}|}{2\sum_{k_1=1}^K\sum_{k_2=1}^K \theta_{ik_1}},
\end{equation}
where $\theta_{ik}$ denotes the predicted proportion of topic $k$ in the collection of responses by individual $i$. The variable ranges from 0 (response focuses on single topic), to 1 (every topic has the same proportion). Mathematically, this conceptualization is equivalent to the Gini-coefficient, which measures the degree of inequality in income distributions (although the direction has been reversed such that a value of 1 implies a perfectly equal distribution).

Lastly, sophisticated individuals should hold opinions about each political actor or policy that they are asked to discuss. As such, shophisticates should be able to express their attitudes towards each open-ended probe in terms of both, approval or disapproval. Responses that reflect high levels of sophistication should therefore display a greater level of \textbf{opinionation}, which is measured as the relative mean absolute difference of relative response lengths for each open-ended response:
\begin{equation}
\text{opinionation}_i = 1-\dfrac{\sum_{j_1=1}^J\sum_{j_2=1}^J |p_{ij_1} - p_{ij_2}|}{2\sum_{j_1=1}^J\sum_{j_2=1}^J p_{ij_1}},
\end{equation}
where $p_{ij}=\tfrac{n_{ij}}{\sum_{j=1}^J n_{ij}}$ is the proportion of words in the response of individual $i$ to question $j$ relative to the overall size of the individuals' response. Again, the variable ranges from 0 (only one question was answered) to 1 (all questions were answered with the same word length per answer).

Together, the three measures form a composite metric of political sophistication by calculating their respective average for each respondent. Like each individual component, the resulting \textbf{text-based sophistication} score ranges from 0 to 1:
\begin{equation}
\text{text-based sophistication}_i = \tfrac{1}{3}(\text{length}_i + \text{topic diversity}_i + \text{opinionation}_i).
\end{equation}

Overall, a highly sophisticated individual can be expected to respond to a set of open-ended items by giving a more elaborate response that focuses on multiple considerations or topics and addresses his or her attitudes towards all relevant political actors or policies more or less equally.


% QUESTION: Validate measure before actual application? I think that would make sense

% QUESTION: think about other factors determined by political sophistication

% CONTINUE HERE

\section*{An Overview of Data Sources}


\subsection*{ANES 2012}

The following analyses are based on the 2012 American National Election Study (ANES), which consists of a representative survey of 5914 adults in the months before the 2012 US Presidential election. 2054 respondents participated in face-to-face interviews while the remaining 3860 filled out the survey online. For the purpose of the present analysis, I rely on the pooled dataset while controlling for differences in survey mode. 

The text-based sophistication measure is based on open-ended questions in which respondents were asked in the pre-election wave of the survey to list anything in particular that they like/dislike about the Democratic/Republican party as well as anything that might make them vote/not vote for either of the Presidential candidates. They were probed by the interviewer asking ``anything else?'' until the respondent answered ``no''. Overall, there are a total number of 8 open-ended responses where individuals described their beliefs and attitudes towards political actors. Verbatim responses were pre-processed using the Aspell spell-checking algorithm (\url{www.aspell.net}). Individuals who did not respond to all of the open-ended items (417 individuals), or who responded in Spanish (228 individuals), were excluded from the analysis.\footnote{Please see Appendix A for descriptive information on the individual components of the text-based sophistication measure.}

\subsection*{Yougov data}

The following analysis will replicate and extend the main results of the previous section using a different survey employing an alternative set of open-ended responses. The data consist of a YouGov survey of 1000 US citizens that was conducted in December 2015. As part of this study, respondents were asked to report in a closed format whether they favor or oppose stricter gun laws. Subsequently, they are asked to respond to the following two questions in verbatim:
\begin{itemize}
\item Still thinking about the question you just answered, what thoughts came to mind while you were answering that question? Please try to list everything that came to mind.
\item Thinking about the mass shootings that have occurred in the U.S. in the last few years, what factors do you think are responsible for the shootings?
\end{itemize}
Similarly, the respondents report on their attitudes towards the Affordable Care Act in a closed format and are then asked to elaborate in their own words by answering the following questions:
\begin{itemize}
\item Still thinking about the question you just answered, what thoughts came to mind while you were answering that question? Please try to list everything that came to mind.
\item For decades, experts have observed that the United States spends far more per person on health care than any other country. However, the U.S. falls behind on most measures of health care outcomes, such as life expectancy. What factors do you think are responsible for the state of our health care system?
\end{itemize}
Here, the text-based sophistication measure is computed based on the verbatim responses to the four preceding questions using the same procedures described in Study 1. Compared to the open-ended likes/dislikes items included in the 2012 ANES, the questions directly address considerations related to specific policy issues.\footnote{Please see Appendix B for descriptive information on the individual components of the text-based sophistication measure.}

Equivalent to the previous analysis, I begin by comparing text-based sophistication to a conventional political knowledge metric. The \textbf{factual knowledge} score in the YouGov data is based on a battery of eight items similar to the knowledge questions in the ANES. Additionally, the YouGov study included a task where respondents read a newspaper article about a fictional infectious disease and were subsequently asked to recall information provided in the article (e.g. regarding symptoms, modes of contraction etc.). I compute an additive index counting the pieces of information that were correctly recalled (\textbf{disease information}) as a measure of the ability to retrieve information from a news article on a non-partisan issue that is related to public health policies.



\section*{Validation: Political Sophistication Should Promote...}

In the following, the text-based sophistication measure is compared to multiple alternative metrics of political knowledge. The most common way to measure political knowledge in surveys is to ask a set of factual questions about political institutions. The 2012 ANES includes such a basic item battery, inquiring for example about the number of times an individual can be elected President of the United States, or how the current U.S. federal budget deficit compares to the deficit in the 1990s. I combine individual responses on these items to a standard additive measure of \textbf{factual knowledge} about politics. Additionally, the in-person sample of the 2012 ANES includes \textbf{interviewer assessments} of each respondent's political sophistication.
% TODO: add citation for use of both knowledge measures

% EXTEND: add relationship with personality measures, examine relationship with extremity, ambivalence, etc.

Figure~\ref{fig:corplot} provides a first validation of text-based sophistication by comparing it to the conventional knowledge metrics. The figure presents scatterplots between individual measures (lower triangular), univariate densities (diagonal), and correlation coefficients (upper triangular). The text-based sophistication measure is positively correlated with both conventional metrics while capturing some additional variation.

\begin{figure}[h]\centering
\includegraphics{../fig/corplot_pres.pdf}
\caption{Correlation matrix of conventional political knowledge metrics and the text-based sophistication measure. The plots on the diagonal display univariate densities for each variable. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient. All correlations reported are statistically significant with $p<.05$.}\label{fig:corplot}
\end{figure}

Interestingly, we observer a stronger correlation between text-based sophistication and interviewer evaluations than between factual knowledge and interviewer evaluations. The text-based measure therefore appears to capture characteristics that influence subjective assessments of sophistication. The interviewers certainly form their impressions throughout the entire survey, but it the complexity of a respondent's verbatim answers seems to be more influential than their performance on the factual knowledge questions.

Overall, while text-based sophistication and the alternative measures are clearly correlated, the relationship between each metric is far from perfect. To provide some intuition whether the variation in text-based sophistication is theoretically meaningful, I present an example of open-ended responses of two individuals who scored equally on the factual knowledge score (3 out of 5 correct responses), but varied highly in text-based sophistication. The results are presented in Table~\ref{tab:ex1}.

\begin{table}[ht]\footnotesize\centering
\begin{tabular}{l|p{6.5cm}|p{6.5cm}}
   \toprule
  & A: Low Sophistication Response & B: High Sophistication Response \\ 
   \midrule
   Obama (+) & The healthcare, keeping that and the financial aid, helping students. & I think he is honest, has good intentions. \\ \hdashline
     Obama (-) &  & I don't feel he is up for the job, he doesn't really know how to get things accomplished from idea to actual reality. \\ \hdashline
     Romney (+) &  & He comes across as an honest person and I feel that financially he would be better for the country. \\ \hdashline
     Romney (-) & By taking financial aid away from students, taking family type planning, healthcare type of help away. & I am a moderate conservative and there are some things about anti-gay rights that I don't support. \\ \hdashline
     Democrats (+) & Mostly the healthcare, mostly people do need healthcare and can't afford to pay insurance. Financial aid most people cant afford to go college. Main two things that I like is the help with education and to pay for insurance to go to doctor. & They do seem to be generally concerned with everyone, taking care of the country as a whole. \\ \hdashline
     Democrats (-) &  & They fight too much among themselves and I disagree with wealth redistribution. \\ \hdashline
     Republicans (+) &  & I agree with a lot of the conservative values and taking responsibility for one's own actions. \\ \hdashline
     Republicans (-) &  & They argue too much among themselves and don't accomplish very much. \\ 
    \bottomrule
 \end{tabular}
\caption{Example of open-ended responses for low and high scores on the text-based sophistication measure with equal factual knowledge scores (3 out of 5 correct responses). Column A displays the verbatim responses of an individual who scored low on the text-based sophistication measure and column B displays the verbatim responses of an individual who scored high on the text-based sophistication measure. Each row represents one of the likes/dislikes items included in the analysis. Note that the responses in this table were slightly redacted for readability (spelling errors removed, etc.).}\label{tab:ex1}
\end{table}

Each row in the table represents one of the open-ended responses (like/dislike for each candidate/party). Column A displays the responses of an individual who scored low on text-based sophistication and column B displays the responses of a high scoring individual. Cells are empty if a respondent refused to provide a response. Even though both individuals received are measured to be equal in their factual political knowledge, there are systematic differences in their response behavior that can be attributed to their political sophistication. Overall, respondent A provided a less elaborate response, only focused on two issues (health care and student loans), and did not report attitudes on multiple items. Compared to B, such a response pattern is suggestive of a less sophisticated political belief system. This initial validation suggests that the variation in the sophistication measure captures meaningful differences in response behavior that clearly overlaps with traditional knowledge metrics while displaying some unique variation.


\subsection*{... Engagement and Participation in Politics}


Political sophistication is not only of theoretical interest as a dependent variable in political science research, but commonly used as a determinant of other outcomes related to attitudes and behavior. As a last validation of text-based sophistication, Figure~\ref{fig:knoweff} presents the effects of each sophistication measure on four dependent variables commonly related to political sophistication: internal efficacy, external efficacy, non-conventional participation, and turnout. The results for the first three dependent variables are based on linear regressions while the effects on turnout are estimated using a logit model. Each model equation includes a single sophistication measure while controlling for gender, education, income, age, race, religiosity, and survey mode (face-to-face vs. online). Each plot displays the difference in the expected value of the respective dependent variable for maximum and minimum values of each sophistication measure, while holding all other variables at their means.

\begin{figure}[h]\centering
\includegraphics{../fig/knoweff_pres.pdf}
\caption{Effects of sophistication on internal efficacy, external efficacy, non-conventional participation, and turnout. For each dependent variable, the figure displays the difference in expected values between maximum and minimum levels of sophistication observed on each measure (including 95\% confidence intervals). Model estimates are based on OLS (internal efficacy, external efficacy, non-conventional participation) or logistic regressions (turnout). Each sophistication measure is included in a single equation while controlling for gender, education, income, age, race, church attendance, and survey mode. Full model results ar presented in the appendix, Tables \ref{tab:inteff} through \ref{tab:turnout}}\label{fig:knoweff}
\end{figure}
% TODO: add estimation controlling for all other factors

Overall, the sophistication metrics perform similarly as predictors of internal efficacy, external efficacy, non-conventional participation, and turnout. The effect of text-based sophistication on the participation measures is even stronger than the effect factual knowledge. This finding is especially noteworthy since the item batteries to measure factual political knowledge in the ANES are selected and validated based on their strong relationship with turnout and participation. 
% TODO: add citation for participation claim



\subsection*{... Precise Positioning of Parties and Candidates}

\subsection*{... Stable Preferences}

\subsection*{... Incorporation of New Information}

\subsection*{... Justified Political Decisions}

\section*{Robustness Check: Personality and Open-Ended Responses}


\section*{Application: The Gender Gap in Political Knowledge}




\subsection*{Study 2: 2015 YouGov Survey}
% We can also look at a different set of open-ended items related to political attitudes!
% TODO: How can I cite Jenn here? Add survey information (questionnaire etc.) in the appendix




Figure~\ref{fig:yg_corplot} examines the distribution of each measure of political knowledge as well as their respective correlations in the YouGov data. Again, we observe that text-based sophistication and factual political knowledge are positively correlated, which indicates that the text-based sophistication measure overlaps with traditional knowledge metrics while capturing unique variation in individual response behavior. Interestingly, there appears to be a stronger relationship between text-based sophistication and disease information than between factual political knowledge and disease information.

\begin{figure}[h]\centering
\includegraphics{../fig/yg_corplot.pdf}
\caption{YouGov data -- Correlation matrix of text-based sophistication, a conventional political knowledge metric, and disease information retrieval. The plots on the diagonal display univariate densities for each variable. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient. All correlations reported are statistically significant with $p<.05$.}\label{fig:yg_corplot}
\end{figure}

Recall that the disease information score can be interpreted as an indicator of the ability to retrieve specific information provided in a news article about a public health issue. It could be argued that text-based sophistication is more similar to the disease information score in that it captures the extent to which participants were able to recall political information that is relevant to their own attitudes. Conventional knowledge scores, on the other hand, inquire about specific that are not necessarily relevant to derive well-informed attitudes about political issues.


\section*{Application: Assessing the Gender Gap}
% APPENDIX: add additional analyses controlling for wordsum score, substantive results are unchanged

%One example for such potential misclassifications is the issue of gender differences in sophistication. On the basis of conventional factual knowledge scores, women frequently appear to be less informed about politics than men \citep{verba1997knowing,wolak2011roots}. However, some scholars suggested that these differences might be rooted in the conceptual and methodological issues related to the measurement approach. For example, \citet{mondak2004knowledge} argue that at least part of the gender gap in sophistication can be attributed to the fact that women are less likely to guess than men when facing a factual knowledge question for which they do not know an immediate answer. Others suggest that the gap can be attenuated by focusing on gender-relevant political knowledge \citep[e.g.,][]{dolan2011women} or by providing policy-specific information \citep[e.g.,][]{jerit2017revisiting}.


A common finding in research on political sophistication is the fact that women appear to be less knowledgeable about politics than men. For example, \citet{verba1997knowing} report that women score lower on political information, interest, and efficacy, which decreases their respective levels of political participation. Importantly, the authors argue that the gender differences can only partly be explained by resource-related factors such as individual levels of education. The authors ascribe the differences in political information and interest to a ``genuine difference in the taste for politics'' between men and women, which they suspect to be driven by socialization \citep[see also][]{wolak2011roots}.

Another explanation for the finding that disparities in resources (e.g., education) cannot fully account for gender differences is the fact that men and women benefit differently from the factors that increase political information \citep{dow2009gender}. As such, the gap is not only due to varying resource levels, but also due to differential gains from the resource itself. More broadly, this finding suggests that men and women consume political information through different channels \citep[see also][]{pietryka2013analysis}. Nevertheless, recent research showed that the gender gap can be substantially decreased given exposure to sufficient information \citep[e.g.][]{jerit2017revisiting} or through deliberation \citep{fraile2014does}.

Other scholars focused more closely on issues related to the measurement of political knowledge in order to explain the apparent gender gap. For example, \citet{mondak2004knowledge} suggest that women are more likely to report that they do not know the answer to a knowledge item if they are not completely certain, whereas men are more inclined to guess. Correcting for the systematic differences in the propensity to guess mitigates the gender gap in knowledge but does not eliminate it completely \citep[see also][]{lizotte2009explaining}. Based on their empirical evidence, \citet{mondak2004knowledge} elaborated on best practices regarding the measurement of political knowledge (e.g., using closed rather than open-ended knowledge items and discouraging `Don't Know' responses). Other related aspects of the survey context have also been shown to affect gender differences in political knowledge. For example, \citet{mcglone2006stereotype} present evidence that the gender gap is exacerbated in an environment that induces stereotype threat, for example if women are aware of the fact that the study focuses on gender differences or if they are interviewed by a male interviewer. However, gender differences are not only induced by \textit{how} researchers ask their questions, but also by the question \textit{content} itself. For example, \citet{dolan2011women} argues that the gap can be closed by focusing on gender-relevant political knowledge items such as information about women's representation in the federal government. Similarly, \citet{stolle2010women} report that the gender gap disappears when people are asked about more practical issues related to the government (e.g., benefits and services).

Overall, the gender gap has been shown to be influenced by how we ask for political information in surveys, as well as the kind of knowledge that is required for a correct response. Indeed, a comprehensive cross-national analysis of election studies in 47 countries between 1996 and 2011 suggests that question format and content account for large portions of the variance of gender disparities in political knowledge \citep{fortin2016cross}.


\subsection*{Study 1: 2012 American National Election Study}

How do men and women compare on the different metrics of political sophistication in the 2012 ANES? Figure~\ref{fig:meandiff} displays the average levels of text-based sophistication as well as the remaining metrics comparing both genders. While we observe a sizable gender gap for both conventional political knowledge measures, the difference is substantially smaller for text-based sophistication. Here, the gender gap is still statistically significant, but substantively inconsequential when compared to the remaining measures.

\begin{figure}[h]\centering
\includegraphics{../fig/meandiff_pres.pdf}
\caption{The gender gap in political sophistication. The figure displays mean levels of sophistication for each measure comparing men and women (including 95\% confidence intervals). The y-axis is scaled to range up to the maximum value observed in the data for each sophistication metric. All gender differences are statistically significant with $p<.05$.}\label{fig:meandiff}
\end{figure}

As described above, at least part of the gender gap can be attributed to real differences in resources relevant to political information (e.g., education). Accordingly, we need to control for common determinants of political knowledge across all available measures to provide a more comprehensive examination of potential gender differences. Previous studies consistently showed that political knowledge is positively related to high media exposure, frequent political discussions, education, and income. Furthermore, I include age, race, religiosity, and survey mode (face-to-face vs. online) as additional control variables. Figure~\ref{fig:determinants} displays the coefficients of regression models with each knowledge/sophistication measure as the dependent variable.

\begin{figure}[h]\centering
\includegraphics{../fig/determinants_pres.pdf}
\caption{Common determinants of political sophistication. Estimates are OLS regression coefficients with 95\% confidence intervals. Dependent variables are the text-based sophistication measure as well as conventional metrics of political knowledge. Full model results are presented in the appendix, Table~\ref{tab:determinants}}\label{fig:determinants}
\end{figure}
% NOTE: rescale knowledge variables to unit variance? the effects would be better to compare...

After controlling for common determinants, text-based sophistication reveals no significant differences between men and women. On the other hand, we still observe the gender gap using all remaining political knowledge metrics considered here. As such, women might not score as highly on political quizzes (partly because they are less likely to guess rather express lack of knowledge), but they do not differ substantially in complexity and sophistication when they describe their political preferences.

The patterns for the remaining determinants are quite similar across different dependent variables. Knowledge and sophistication is significantly higher among respondents who are more exposed to political news media, discuss politics frequently, are more educated, and have higher income. An interesting deviation, however, is the effect of survey mode. For factual knowledge questions, we observe that respondents in online surveys score significantly higher than individuals in face-to-face interviews. This difference could be explained by the fact that individuals are able to look up responses to factual knowledge questions while taking an online survey \citep[see also][]{clifford2016cheating}. For the text-based measure, on the other hand, we see that individuals appear to score lower on sophistication in online surveys. Respondents in online surveys therefore seem less willing to elaborate on their attitudes. Overall, the fact that the determinants of political sophistication are very consistent across models lends additional validity to the text-based measure.



\subsection*{Study 2: 2015 YouGov Data}

Next, I examine whether the results regarding the gender gap observed in Study 1 are replicated in the YouGov data. Figure~\ref{fig:yg_meandiff} compares the alternative measures of political knowledge and sophistication for men and women. As before, we observe a significant gender gap in factual knowledge (middle panel), which disappears using the text-based measure (left panel). Furthermore, there is no apparent gender gap in disease information retrieval. If anything, women are able to recall slightly more accurate information about the infectious disease described in the news article. This result is consistent with recent research by \citet{jerit2017revisiting}, which suggests that knowledge gaps between men and women disappear upon receiving sufficient information.

\begin{figure}[h]\centering
\includegraphics{../fig/yg_meandiff.pdf}
\caption{YouGov data -- The gender gap in political sophistication. The figure displays mean levels of sophistication for each measure comparing men and women (including 95\% confidence intervals). The y-axis is scaled to range up to the maximum value observed in the data for each sophistication metric. The gender difference in factual knowledge is statistically significant with $p<.05$.}\label{fig:yg_meandiff}
\end{figure}

A skeptical reader may again argue that the difference in factual knowledge between men and women could potentially be explained by systematic differences in resource-related factors. As such, we need to examine whether the gender gap persists even after controlling for covariates that might influence political knowledge. Similar to the analyses discussed in Study 1, Figure~\ref{fig:yg_determinants} presents the results of linear regressions predicting each measure as a function of gender, education, income, age, race, and religiosity.

\begin{figure}[h]\centering
\includegraphics{../fig/yg_determinants.pdf}
\caption{Common determinants of political sophistication -- Replication using YouGov data. Estimates are OLS regression coefficients with 95\% confidence intervals. Dependent variables are the text-based sophistication measure, factual political knowledge as well as knowledge about a fictional disease that was presented as part of the study. Full model results are presented in the appendix, Table~\ref{tab:yg_determinants}}\label{fig:yg_determinants}
\end{figure}

As before, men do not perform better than women on text-based sophistication or disease information retrieval in a multivariate setting. However, the gender gap in factual political knowledge persists and is substantively as well as statistically significant. The remaining determinants of sophistication/knowledge are similar across measures (except for family income). Interestingly, the observed pattern of effects on text-based sophistication is strikingly similar to the effects on information retrieval about the fictional disease. This result reinforces the conclusion that text-based sophistication and disease information retrieval in the YouGov study share common characteristics in the sense that they capture how individuals recall considerations that are relevant to their own attitudes rather than inquiring about facts related to political institutions and elites that are extraneous to the issues at hand.


\begin{figure}[h]\centering
\includegraphics[scale=.6]{../fig/ggjoy.pdf}
\caption{Swiss data -- Political sophistication and level of justification.}\label{fig:swiss_ggjoy}
\end{figure}

% REVISE: Make a reference to Jenn's study, which found that gender differences disappear if information is provided to respondents

% TODO: add section with LI survey data?
% issue: doesn't contain conventional political knowledge score
% but I could examine party identification as a determinant of political sophistication

% IDEA: out-party sophistication vs. in-party sophistication?
% I could split up the measure by in-party vs. out-party and examine
% the difference as an indicator of political tolerance etc.
% maybe there is an item that examines whether people would revise their vote choice etc. after the election and I could compare traditional knowledge vs. text-based sophistication.


\section*{Conclusion}
% lot's of potential extensions, think about standardizing the measure to make it more comparable across contexts
% Zaller argues that it captures what actually got into people's minds... that's a perfect argument for open-ended responses! check also the druckman paper.
% Make a connection to political competence, we shouldn't care as much about political knowledge that is favored by elites, but rather examine whether individuals are able to discuss their political views in a coherent way. Seen that way, one could make an argument that political competence captures the extent to which individuals are able to incorporate new information.
% What is a competent citizen? One who has good reasons for his or her attitudes... we can measure that when examining how repondents talk about their political beliefs.

As Arthur Lupia \citeyearpar{lupia2015uninformed} described in his recent book ``Uninformed'', political scientists should worry less about pure levels of \textit{information}, but rather focus on the necessary conditions for individuals to make \textit{competent} decisions. Competence in the context of political decision-making and voting requires citizens to hold informed attitudes about their representatives. Factual knowledge about political institutions might be a useful proxy for competence in certain scenarios. However, it cannot address directly whether individuals are sufficiently opinionated about political actors they try to hold accountable. In comparison, the text-based sophistication measure proposed here is agnostic about the specific contents of individual beliefs, but directly captures the structure and complexity in attitude expression.

The findings presented in this paper show that conventional knowledge indices and the text-based measure share a substantial amount of variance. However, they are far from being identical and capture different aspects of sophistication. Most importantly, using the text-based measure, any evidence for the gender gap commonly reported using factual knowledge scales disappears. Women might know fewer facts about political institutions, but they do not differ substantively in the complexity of their expressed political beliefs.


\singlespacing
\bibliographystyle{/data/Dropbox/Uni/Lit/apsr2006}
\bibliography{/data/Dropbox/Uni/Lit/Literature}

\clearpage
\section*{Appendix A: Open-ended Responses in ANES}
\renewcommand\thefigure{A.\arabic{figure}}
\renewcommand\thetable{A.\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}


% COMBINE: combine histograms etc. for different datasets in a single plot...

\begin{figure}[h]\centering
\includegraphics{../fig/wc.pdf}
\caption{Histogram of total word count in the collection of open-ended responses for each individual (left panel) and distribution of logged word count used in the text-based sophistication measure (right panel, re-scaled to range from 0 to 1). Dashed red lines indicate mean values. Most respondents provide brief statements when they describe their attitudes towards political parties and candidates. The mean response length to all 8 questions is about 75 words, so an average response to a single question consisted of less than 10 words, omitting respondents who did not provide any information.}\label{fig:wc}
\end{figure}

\begin{figure}[h]\centering
\includegraphics{../fig/diversity.pdf}
\caption{Histogram and density of the topic diversity (left panel) and opinion diversity (right panel) measure. Dashed red lines indicate mean values. The spike at 0 for opinion diversity are due to the fact that a large proportion of respondents only answered a single open-ended question.}\label{fig:diversity}
\end{figure}


\clearpage
\section*{Appendix B: Open-ended Responses in YouGov Data}
\renewcommand\thefigure{B.\arabic{figure}}
\renewcommand\thetable{B.\arabic{table}}
\setcounter{figure}{0}
\setcounter{table}{0}

\begin{figure}[h]\centering
\includegraphics{../fig/yg_wc.pdf}
\caption{Histogram of total word count in the collection of open-ended responses for each individual (left panel) and distribution of logged word count used in the text-based sophistication measure (right panel, re-scaled to range from 0 to 1). Dashed red lines indicate mean values. Most respondents provide brief statements when they describe their attitudes towards political parties and candidates. The mean response length to all 8 questions is about 73 words, so an average response to a single question consisted of approximately 18 words, omitting respondents who did not provide any information.}\label{fig:yg_wc}
\end{figure}

\begin{figure}[h]\centering
\includegraphics{../fig/yg_diversity.pdf}
\caption{Histogram and density of the topic diversity (left panel) and opinion diversity (right panel) measure. Dashed red lines indicate mean values. The spike at 0 for opinion diversity are due to the fact that a large proportion of respondents only answered a single open-ended question.}\label{fig:yg_diversity}
\end{figure}




%\clearpage
%\section*{Appendix C: Tables of Model Estimates}
%\renewcommand\thefigure{C.\arabic{figure}}
%\renewcommand\thetable{C.\arabic{table}}
%\setcounter{figure}{0}
%\setcounter{table}{0}
%
%\input{../tab/inteff}
%\input{../tab/exteff}
%\input{../tab/nonconv}
%\input{../tab/turnout}
%\input{../tab/determinants}
%\input{../tab/closing}
%\input{../tab/yg_determinants}

\end{document}