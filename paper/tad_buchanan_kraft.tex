\documentclass[12pt]{article}
\usepackage[margin = .75in]{geometry}
\usepackage[USenglish]{babel}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{lscape}
\usepackage{dcolumn}
\usepackage{xcolor}
\usepackage[colorlinks=true,citecolor=red!50!black,urlcolor=blue!50!black,linkcolor=red!50!black]{hyperref}

\author{Laura Buchanan\footnote{\href{mailto:lcb402@nyu.edu}{lcb402@nyu.edu}} \and Patrick Kraft\footnote{\href{mailto:pk1622@nyu.edu}{pk1622@nyu.edu}}}
\date{today}

\title{Don't Just Ask Me for Facts!\\
\large{Measuring Political Sophistication using Open-Ended Responses}}
\date{\today}

% sans serif font
\renewcommand{\familydefault}{\sfdefault}


\begin{document}
\maketitle\doublespacing\thispagestyle{empty}

\begin{abstract}
There is a broad consensus among scholars of political science and public opinion that the American electorate is not well informed about politics. However, there is no agreement in the discipline about \textit{how to measure} how little citizens actually know. While many studies rely on simple factual political knowledge questions to assess political sophistication, others have criticized this approach from methodological and theoretical perspectives, claiming it does not provide a valid measure of the concept of interest. We propose a new measure of political sophistication based on open-ended survey responses about individual political attitudes and preferences. Using conventional political knowledge metrics and open-ended responses from the 2012 American National Election Study (ANES), we consider word count, response diversity, topic diversity, and a novel aggregate weighted measure to show that ...

\vspace{\baselineskip}
\noindent \textbf{Keywords:} political sophistication, measurement, open-ended responses, structural topic models \\

\noindent \textbf{Word Count:} ...
\end{abstract}
\newpage\setcounter{page}{1}



\section{Introduction}

On of the fundamental concepts in the study of political attitudes and behavior is political sophistication and knowledge \citep{converse1964nature,carpini1996americans}. While most scholars emphasize how little people know about politics, the question of how to assess individual knowledge has been subject to re-occurring scholarly debate \citep[e.g.][]{mondak2000reconsidering,mondak2001asked,sturgis2008experiment,debell2013harder,pietryka2013analysis}. Many analyses exclusively rely on individual levels of political knowledge measured by correctness of factual knowledge questions. However, recent research points to important differences between types of knowledge questions that have previously been disregarded \citep{barabas2014question}, such as distinguishing between policy-specific and general knowledge questions. Furthermore, scholars argue that factual political knowledge as measured in many surveys may not be theoretically relevant \citep[e.g., the question writer and respondent have differing world-views]{lupia2006elitism}. Rather, the conceptualization of political sophistication should take into account how people structure their attitudes and beliefs \citep[e.g.][]{luskin1987measuring}. As such, measuring sophistication solely based on answers to political trivia may misclassify respondents who cannot recall these facts, but do indeed have a coherent cognitive framework of political ideas.

We propose an alternative measure of political sophistication based on an individual's responses to open-ended questions about their attitudes towards major parties and presidential candidates. We make inferences about the respondents' level of political sophistication and belief constraints by focusing on \textit{how} respondents describe their preferences and beliefs. More specifically, we consider the diversity in topics raised by respondents. Topic diversity will be measured using structural topic models \citep{roberts2014structural}. Furthermore, we consider additional characteristics of individual open-ended responses, such as response length and diversity between opinions. Our aim is to assess the degree to which political attitudes are structured and expressed in a more complex manner than discernible form correctness on a factual questionnaire. We suspect that the diversity in topics a respondent discusses, or the detail with which they speak about the topics they mention, will covary with other political knowledge measures. We therefore compare the text-based measures to common factual knowledge items as well as the interviewer assessment of the respondent's political knowledge as benchmarks for political sophistication. This text based analysis will likely be conceptually closer to the actual structure and constraint of political belief systems \citep[see for example][]{tetlock1983cognitive,luskin1987measuring} than fact based knowledge items can capture.
% revise last part depending on evaluation method etc.

Overall, we hope to show that our measure of political sophistication can provide novel insights compared to conventional knowledge measures. Furthermore, developing valid measures of political sophistication based on open-ended responses will provide new opportunities for comparisons of political knowledge across time and contexts.


\section{Political Knowledge and Sophistication}
% 1: defining political participation in the literature
% 2: measuring political sophistication, previous approaches
% 3: issues with previous approaches, criticism

In his seminal study, \citet{converse1964nature} examined the degree to which citizens hold constrained belief systems about politics. In the paper, belief systems are defined as ``a configuration of ideas and attitudes in which the elements are bound together by some form of constraint or functional interdependence'' \citep[207]{converse1964nature}. The analyses showed that the majority of the electorate does not hold structured and constrained belief systems, understand abstract ideological concepts, or hold stable issue positions. 

This pessimistic view regarding the competence of the US electorate has been supported in multiple subsequent analyses. \citet{carpini1996americans} showed that large parts of the American electorate are not sufficiently informed about politics. Furthermore, there are systematic differences in political attitudes and behavior between citizens who are well informed compared to those who are not. Such a finding is problematic from a normative perspective, since it indicates that differences in levels of information can result in unequal representation in the political system \citep[see also][]{althaus1998information,kuklinski2000misinformation,gilens2001political}. However, rather than relying on the degree to which individuals hold constrained belief systems, \citet{carpini1996americans}, conceptualized knowledge as the awareness of key democratic values, which was measured using factual knowledge questions \citep[see also][]{carpini1993measuring}. A broad range of studies focused on similar factual knowledge measures as indicators of sophistication \citep[e.g.][]{zaller1991information,jacoby1995structure,gomez2001political}. Most prominently, \citet{zaller1992nature} argued for the measurement of political awareness using tests of neutral factual information about politics, since they ``more directly than any of the alternative measures, capture what has actually gotten into people’s minds'' \citep[21]{zaller1992nature}. However, other research casts doubt on this assertion, both from methodological as well as theoretical perspectives.

Methodologically, many studies raised issues related to the validity of factual knowledge questions. One fundamental problem discussed in the literature are potential biases due to guessing \citep{mondak2000reconsidering,mondak2001developing,mondak2001asked,miller2008experimenting}. Knowledge items that offer a ``Don't Know'' option essentially convolute two very distinct concepts: the individual information level as well as the propensity to guess. Based on this argument, \citet{mondak2004knowledge} showed that conventional knowledge measures overestimated the gender gap in political knowledge due to the fact that male respondents are more likely to take a guess if they are not fully informed \citep[see also][for a more recent discussion of differential item functioning as an explanation for knowledge gaps]{pietryka2013analysis}. The conclusions drawn from these studies were to rely on closed rather than open-ended knowledge questions and omitting ``Don't Know'' response options \citep[but see][]{sturgis2008experiment,luskin2011don}. Other scholars further criticized open-ended factual knowledge questions such as those administered in the American National Election Study due to problematic coding rules, which do not accurately capture partial knowledge \citep{krosnick2008problems,gibson2009knowing,debell2013harder}.

Focusing exclusively on factual political knowledge has also been criticized on theoretical grounds. For example, \citet{lupia2006elitism} argued that the information asked for in the item batteries has no clear relevance for individual political participation. Instead, researchers should concentrate on knowledge and heuristics that directly help citizens to make competent political decisions \citep[see also][]{lupia1994shortcuts}. Responses to factual knowledge questions have further been shown to be conditional on the respondents' motivation, their partisanship, as well as monetary incentives in the survey \citep{prior2008money,bullock2015partisan,prior2015you}. Conventional items also differ with regard to the specific dimension of political knowledge they measure \citep{barabas2014question} and ignore important aspects such as visual cues \citep{prior2014visual}.

Overall, the studies discussed so far suggest that the conventional item batteries have problematic measurement properties. More importantly, however, some authors raised doubts whether factual political knowledge actually captures the phenomena that are ultimately most interesting for scholars of public opinion. \citet{converse1964nature} initially discussed the level of constraint in political beliefs rather than isolated pieces of factual information about the political system. Other scholars emphasized similar conceptualizations of political sophistication. \citet{tetlock1983cognitive}, for example, used the term \textit{integrative complexity} to describe the variety and integration of considerations related to an issue. It is important to note that here, sophistication is not based on the content (or accuracy) of related considerations but rather on its \textit{structure}. \citet{luskin1987measuring} also defined political sophistication based on the structure of individual belief systems. More specifically, the author argues that belief systems can vary on three separate dimensions: (1) their \textit{size} -- i.e. the number of cognitions, (2) their \textit{range} -- i.e. the dispersion of cognition over categories, and (3) their \textit{constraint} -- i.e. the extent to which cognitions are interconnected. Political sophistication, in turn, is seen as the conjunction of these dimensions: ``A person is politically sophisticated to the extent to which his or her [political belief system] is large, wide-ranging, and highly constrained.'' \citep[860]{luskin1987measuring}.

Such a conceptualization of political sophistication seems theoretically more interesting and useful than simple tests of factual information. However, why does such a large body of literature in political science and public opinion then only focus on knowledge questions? One answer to this question is provided in the early study by \citet[206]{converse1964nature}, who stated: ``what is important to study cannot be measured and that what can be measured is not important to study.'' Factual political knowledge is much easier to assess (albeit not perfectly) than the structure of political belief systems. Indeed, \citet{tetlock1983cognitive} had to rely on manual coding of policy statements of US senators in order to assess their degree of integrative complexity. Such manual coding procedures, however, become increasingly infeasible with large amounts of text data (such as in large surveys). Advances in automated text analyses, on the other hand, provide us with the necessary tools to derive a measure of political sophistication that captures the theoretical arguments put forward by \citet{converse1964nature}, \citet{tetlock1983cognitive} and \citet{luskin1987measuring}, without the necessity of human coders. In the following, we will derive and explore such a measure based on open-ended survey responses.


\section{Measurement Approach}
% 1: describe measure and how it relates to theoretical conceptualization of sophistication (see Luskin's definition)
% 2: how are open-ended responses administered, potential issues
% 3: conclusion: coding open-ended responses gets us closer to the definition of political sophistication that we are actually interested in!

We propose that the the dimensions laid out by \citet{luskin1987measuring} --- size, range, and constraint of political belief systems --- can be measured by directly examining how individuals describe their political attitudes and beliefs. More specifically, we will consider individual responses to a set of open-ended questions where respondents were asked to describe aspects that they liked and disliked about both major parties and presidential candidates before the 2012 US election. Considering likes and dislikes separately, there are a total number of 8 open-ended responses where individuals describe their beliefs and attitudes towards political actors. Table~\ref{tab:measure} summarizes how different characteristics of open-ended responses can be matched to the aspects of political sophistication discussed previously.

\begin{table}[h]
\begin{tabular}{ll}
\hline 
Dimension of political belief system & Characteristic of open-ended response \\
\hline
Size (number of cognitions) & Overall length of responses \\
Range (dispersion of cognitions over categories) & Diversity in topics raised in responses \\
Constraint (interconnectedness of cognitions) & Diversity in response length between items \\
\hline
\end{tabular}
\caption{Aspects of political sophistication and its measure in open-ended responses.}\label{tab:measure}
\end{table}

The size of the political belief system can simply be captured as the overall length of individual responses. If people possess a larger number of considerations related to political parties and candidates, then this should be reflected in the  overall collection of their responses describing their attitudes and beliefs.

The range of cognitions over categories could be measured as the diversity in topics raised in individual responses. If individuals hold more diverse cognitions towards political actors, we should observe that they address a wider range of topics in their responses, rather than focusing on an isolated issue to describe their preferences.

The last dimension, the degree of constraint or interconnectedness of cognitions, is more difficult to capture in an automated way based on characteristics of an open-ended response. While we cannot directly measure the interconnectedness of cognitions, we argue that the diversity in response length between items could be used as a possible proxy. In order to see why this is the case, consider two hypothetical individuals who possess a belief system of similar size and range. Accordingly, we would expect that their open-ended responses should be of similar overall length and have a comparable degree of diversity in topics. Now, suppose that for one individual, the belief system is highly interconnected, and for the other individual it is not. Holding the overall length and topic diversity of their set of responses constant, higher interconnectedness allows individuals to spread their response topics more homogeneously across items. In other words, if considerations were not interconnected, then responding to likes as well as dislikes (for party/candidates of in/out-party), would require an increase in the overall length and diversity of the response. As such, distributing responses across different items can be seen as a proxy for interconnectedness of cognitions.

Of course, the measurement strategy derived here makes strong implicit assumptions about the nature of political belief systems. However, the sole purpose of this short discussion was to suggest potential links between the theoretical construct and measurable characteristics of open-ended responses. Ultimately, it is an empirical question, as to whether these characteristics provide valid measures of political sophistication. Before we turn to the issue of validation, we will discuss the data and methods used in the analyses in more detail.



\section{Data and Methods}
% describe dataset and open-ended responses
% describe measure for each dimension as well as composite measure of sophistication

We use survey data from the 2012 American National Election Study in order to demonstrate and validate  our measure of political sophistication. The dataset consists of 5914 adults (2054 of which participated in face-to-face interviews while the remaining 3860 participated in a representative online survey). While both samples differ slightly with regards to the inclusion of some specific variables, we will mostly rely on the pooled dataset purpose of our analysis.

The knowledge measure is based on open-ended questions in which respondents were asked to list anything in particular that they like/dislike about the Democratic/Republican party as well as anything that might make them vote/not vote for either of the Presidential candidates and were probed by the interviewer asking ``anything else?'' until the respondent answered no. All open-ended responses were pre-processed by correcting spelling errors using an implementation of the Aspell spell checking algorithm in \texttt{R} (\url{www.aspell.net}), and deleting individuals who responded in Spanish (228 individuals). 

As discussed above, we consider three different aspects of the open-ended responses to capture the distinct dimensions of political sophistication discussed above: size, range, and constraint of the political belief system. The \textbf{size} of the belief system is measured as the word count for each individual over all prompts:
\begin{equation}
\text{size}_i = \log\left(\sum_J n_{ij}\right),
\end{equation}
where $n_{ij}$ is the number of words in the response of individual $i$ in response to question $j$. $J$ denotes the set of all likes/dislikes items. We use the log of the count linearize the distribution of responses.

The \textbf{range} of the belief system is captured as the diversity in topics raised by each respondents. We conceptualize diversity as the Shannon-entropy of topic proportions \citep{shannon1948mathematical,munger2016elites}:\footnote{The structural topic model was estimated using the \texttt{stm} package in R \citep{roberts2014structural}. The number of topics was selected using the algorithm of \citet{lee2014low} and the model was estimated via spectral initialization to address the issue of multi-modality \citep[see][for details]{roberts2014stm}. We used measures for age, education, party identification, as well as an interaction between education and party identification as covariates for topic prevalence. This variable selection is equivalent to the procedure model specification described in \citet{roberts2014structural}. We estimated a total number of 72 topics. While we cannot discuss the topics in detail due to limited space, it is worth noting that the results reported hereafter are robust for model specifications with fewer numbers of topics.}
\begin{equation}
\text{range}_i = −\sum_K \theta_{ik} \log_2(\theta_{ik}),
\end{equation}
where $\theta_{ik}$ denotes the predicted proportion of topic $k$ in the collection of responses by individual $i$. The variable ranges from 0 (entire response focuses on single topic), to $\log_2(k=72)$ (every topic has the same proportion).

We use the same logic to measure the diversity in opinions raised across item (as a proxy for constraint/interconnectedness of cognitions):
\begin{equation}
\text{constraint}_i = −\sum_J p_{ij} \log_2(p_{ij}),
\end{equation}
where $p_{ij}=\tfrac{n_{ij}}{\sum_J n_{ij}}$ is the proportion of words in the response of individual $i$ to question $j$ relative to the overall size of the individuals' response.

The three measures are then united to a composite metric of political sophistication. We decided to combined the measures in a multiplicative rather than an additive fashion, because sophistication can be seen as \textit{conjunctive} \citep[see][]{luskin1987measuring}: the separate elements are only effective in combination and are not simple substitutes of each other:
\begin{equation}
\text{sophistication}_i = (\text{size}_i + 1) * (\text{range}_i + 1) * (\text{constraint}_i + 1).
\end{equation}
Note that we added $+1$ to each term in order to assure that the minimum of each individual variable is 1 rather than 0. This way, we are still able to capture variation in sophistication if one of the elements is at its minimum.

We consider a number of conventional political knowledge measures for comparison with our metrics. The variables are summarized in Table~\ref{tab:featextr}. The first three measures are based on additive scales indicating the number of correct responses. The interviewer evaluation (only available in face-to-face sample) is based on a five-point scale that was recorded after the interview (pre-election and post-election wave).

\begin{table}\onehalfspacing\footnotesize
\begin{tabular}{p{5.5cm}p{5.5cm}p{5.5cm}}
\hline
Canonical Political Knowledge Metric &	Abridged Sample Questions &	Name in Figures \\
\hline
Knowledge of Office Recognition  	  & Who is the Speaker of the House? Who is the Vice President? &  Political Knowledge: Office Recognition \\ 
Knowledge of U.S. Political Facts 	 & How many times can someone be elected president? What is the size of the federal deficit? & Political Knowledge: Factual Knowledge\\
Knowledge of Majorities in Congress & What party has the most members in the U.S Senate? & Political Knowledge: Majorities in Congress\\
Pre-Interview Political Knowledge Interviewer Evaluation & --- & Political Knowledge: Knowledge Pre Evaluation\\
Post-Interview Political Knowledge Interviewer Evaluation & --- & Political Knowledge: Knowledge Pre Evaluation\\
Pre-Interview Intelligence Interviewer Evaluation & --- & Political Knowledge: Intelligence Pre Evaluation\\
Post-Interview Intelligence Interviewer Evaluation & --- & Political Knowledge: Intelligence Pre Evaluation\\
Education Level 	 & (1) Less than high school credential&Political Knowledge: Education Level \\
&(2) High School credential&\\
&...&\\
&(5) Graduate School & \\
\hline 
\end{tabular} 
\caption{Methods: Feature Extraction}\label{tab:featextr}
\end{table}

Furthermore, the analyses outlined below will include several control variables such as media usage, frequency of political discussions, gender, age, race, religiosity, ideology, party identification, and interview mode (face-to-face vs. online).
	

\section{Descriptive Results}
% histogram of response length could be useful
% histogram of individual aspects
% show examples of high and low scoring political knowledge
% distribution of knowledge measure
% correlation plot with other knowledge measures (including individual aspects)


\begin{figure}
\includegraphics[width=\textwidth]{../fig/diversity_distributions.png}
\caption{Diversity Distributions and Knowledge Measure}
\end{figure}

\begin{figure}
\includegraphics[width=\textwidth]{../fig/corr_fixed_data.png}
\caption{Correlation Plot of Knowledge Measures}
\end{figure}

\section{Validation Performance}
% replicate common findings
% increase consistency b/w policy attitudes


\paragraph{Ideas for evaluation:}
% replicate common findings, e.g. gender gap in political knowledge \citep[e.g.][]{barabas2014question}
% Increase in consistency b/w policy attitudes \citep[e.g.][]{prior2014visual}


\section{Discussion and Conclusion}


\clearpage\singlespacing\footnotesize
\bibliographystyle{apsr2006}
\bibliography{lit}


\end{document}