% REPLACE: "recall" instead of "factual" knowledge questions
% INTRO: motivate process/structure NOT content

% OUTLINE INTRO %
% 1. Assessing political competence is important, but the measurement debate remains unresolved
% 2. Factual knowledge questions are insufficient, we should focus on what people know and not what they don't know
% 3. This is where my measure comes in, describe basic idea and contribution
% 4. Outline of the paper and describe basic findings + conclusion

One of the most important tasks for citizens in modern democracies is to vote for candidates who represent their interests and to hold elected officials accountable. While there have been longstanding debates about whether citizens are sufficiently informed to fulfill this task, fundamental issues regarding the measurement of knowledge continue to plague the discipline \citep{mondak2001developing,sturgis2008experiment,pietryka2013analysis}. Most analyses rely on survey questions that assess individuals' ability to recall basic facts about political institutions and officeholders \citep[e.g.,][]{zaller1990political,carpini1996americans}.\footnote{Others rely on broader conceptualizations of sophistication that incorporate additional dimensions such as education and income \citep[e.g.,][]{jacoby2006value}.} In principle, these quizzes should cover information that is necessary and/or sufficient for citizens to make competent decisions in a given context \citep{lupia2006elitism}. Yet, determining such a set of relevant items proves to be extremely difficult, especially since there are systematic differences in types of knowledge \citep{barabas2014question}. Even within a given policy area, people may disagree about which facts are crucial for political competence due to inherent value differences \citep{lupia2015uninformed}. 

Given these difficulties, most empirical studies involving political knowledge and competence rely on a set of off-the-shelf recall questions rather than justifying their item selection theoretically. As \citet[219]{lupia2006elitism} points out, ``[m]ost political knowledge questions are not derived from a replicable or transparent logic about how their answers bear on a voter's ability to make decisions of a particular quality.'' It is therefore not surprising that conventional metrics do not properly capture policy-specific information \citep[e.g.,][]{gilens2001political} or other knowledge relevant to citizens' preferences and decision-making \citep[cf.][43--68]{graber2001processing}. In a recent review, \citeauthor{cramer2017fact} eloquently summarize: ``All of this work suggests that we are missing a lot by equating information levels as measured in traditional knowledge batteries with civic competence. By focusing on \textit{what people do not know} rather than what they do know and how they use that information, we are likely missing the empirical reality of citizens' political knowledge'' \citeyearpar[756, emphasis added]{cramer2017fact}.
%In other words, rather than trying to examine how people arrive at their preferences, researchers have turned the logic upside down by measuring which facts citizens do not know, irrespective of whether these facts are necessary for competence or not. In an effort to shift the focus from irrelevant facts citizen's don't know to how they arrive at their preferences...

In an effort to shift the focus directly on \textit{what people do know}, I propose a measure of \textit{discursive sophistication} that is based on how people discuss their political preferences in open-ended survey responses. Specifically, I develop a framework to assess whether beliefs and opinions in a given political domain are expressed in a more elaborate manner---a question that is not directly discernible from off-the-shelf factual knowledge items. The approach is therefore \textit{naive} in that it does not presuppose pieces of information as necessary for political competence but rather examines the respondents' justification of their preferences at face value. Measuring sophistication based on how people talk about politics provides two major advantages compared to off-the-shelf factual knowledge items: (1) it captures the extent to which a respondent's political beliefs are based on elaborate reasoning, and (2) it can easily pinpoint competence in specific areas by incorporating targeted open-ended items.

I validate the measure across multiple data sets by comparing it to conventional factual knowledge scores as predictors of various indicators of competence. While the measures share a considerable amount of variance, they are far from equivalent. Indeed, discursive sophistication is a stronger predictor of turnout and other forms of political participation than traditional metrics. After validating the measurement approach, the paper illustrates how discursive sophistication can help refine previous insights in the literature by re-examining an oft-cited finding in empirical research---the gender gap in political knowledge. Contrary to previous research, I find no evidence for such a gap in discursive sophistication. While women might score lower than men on factual knowledge about political institutions and elites, there are no differences in the complexity of expressed political attitudes. This divergence can be explained by the fact that open-ended responses allow women to focus on different issues than men. Altogether, discursive sophistication is shown to be a useful ancillary measure that expands our understanding of political competence and can help improve the development of new factual knowledge questions.



\section*{Elaborate Reasoning and Attitude Expression}
% Style over Substance?
% In-Depth Processing and Attitude Expression

% OUTLINE THEORY %
% 1. Everyone uses knowledge, and it's usually off-the-shelf stuff
% 2. Since it's infeasible to come up with new knowledge battery for every problem, Druckman argues that we should focus on the process rather than the content/substance
% 3. Previous researchers have induced in-depth processing by asking people to justify their preferences
% 4. I ask the question of how people should justify their preferences if they engage in in-depth processing! 
% 5. Examining how people justify their preferences is also important because that's how social infleunce etc. is transmitted.
% 6. (optional) Segway to discuss how these attributes of elaborate processing and sophisticated belief systems should be expressed in open-ended responses.

%In modern democracies, citizens can engage in politics through various means such as voting in local, state, or federal elections. Depending on the institutional setup, they may also directly decide on specific policies through referenda. A common concern in these contexts is whether citizens are able to make high quality decisions in accordance with their underlying interests. Given that

%Rather than trying to develop recall items that presupposes a set of facts as necessary for political competence, I therefore analyze \textit{how} individuals discuss their preferences related to a given political task.

Most studies on political attitudes and public opinion consider individual political knowledge in one way or another---either directly as an outcome variable of interest, as a major explanatory factor, or as an important confounder to control for. To measure the underlying latent concept, researchers commonly rely on short batteries of standard recall questions on basic facts about the political system. One canonical article proposing such a battery--\citet{carpini1993measuring}--has been cited approximately 800 times between its publication and the writing of this manuscript. Figure~\ref{fig:carpini} shows the yearly citation count over time; the trend illustrates how political knowledge remains a concept of intense scholarly interest---and that it is frequently measured using standard off-the-shelf recall questions.

\begin{figure}[h]\centering
	\includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/cites.pdf}
	\caption[Yearly citation count of \citet{carpini1993measuring}]{Yearly citation count of \citet{carpini1993measuring} based on Google Scholar.}\label{fig:carpini}
\end{figure}

To be fair, it is not always feasible for researchers to develop new sets of knowledge items that specifically target relevant information to make competent decisions in any particular context. Given that there is usually no consensus about what information is necessary in the first place, \citet{druckman2014pathologies} proposes abandoning recall questions as measures of ``quality opinion.'' Instead, the author advocates ``\textit{less} focus on the \textit{content/substance} of opinions [...] and \textit{more} on the \textit{process} and specifically the \textit{motivation} that underlies the formation of those opinions'' \citeyearpar[478, emphasis in the original]{druckman2014pathologies}. The key distinction should therefore be how citizens approach a political issue and whether they are motivated to engage in elaborate reasoning to arrive at their individual decision.
% a useful alternative is to concentrate on whether people are motivated to engage in elaborate reasoning when forming their preferences.

These motivational underpinnings, in turn, have been a subject of lively research in psychology and adjacent fields. In her influential article, \citet{kunda1990case} distinguished between reasoning driven primarily by directional as compared to accuracy goals. People who engage in accuracy-driven reasoning process information more carefully and tend to rely less on biased strategies and cognitive shortcuts. Importantly, experimental evidence suggests that accuracy goals can be activated by telling participants that they have to \textit{justify their beliefs} in front of others \citep{kunda1990case}. There are several notable examples in political science where researchers relied on this strategy to induce in-depth processing by creating the expectation among participants that they have to explain their decisions at some point in the study \citep[e.g.,][]{tetlock1983accountability,redlawsk2002hot,eveland2004effect,bolsen2014influence}.
% also see tetlock1989social

%I argue that we can turn this logic on its head in order to assess the level of elaboration in political reasoning in public opinion surveys. 
I argue that we can turn this logic on its head and assess the extent to which people engage in elaborate reasoning about a political issue by examining \textit{how} they talk about and justify their preferences \citep[see also][]{rosenberg1988structure,rosenberg1988political}. For example, if respondents are motivated and able to engage in in-depth processing to form quality opinions on a specific topic, they should approach it from multiple perspectives and show awareness of arguments for and against certain positions \citep{cappella2002argument}.\footnote{A similar argument is made by \citet{colombo2016justifications} who investigates the competence of Swiss citizens voting in policy referenda. Colombo conceptualizes competence as a voter's ability to justify his or her political decisions, and measures the concept by manually coding open-ended responses to survey questions.} In other words, how people talk about their political preferences provides insights into their underlying motivation to engage in in-depth reasoning and may ultimately allow us to make inferences about their level of sophistication in a specific issue domain.
%Rather than using people's expectation to provide justifications as a manipulation for accuracy motivations, we can therefore directly assess the level of elaboration in political reasoning by examining how people discuss their own views.

There is an additional reason why it is important to consider how people talk about their political preferences when examining citizen competence and sophistication. Political information often reaches citizens indirectly through conversations with coworkers, friends, and family \citep[see][for a recent example]{druckman2018no}. Studies have further shown that political knowledge itself is transmitted through social interactions, especially since people are able to seek out politically competent discussants \citep{huckfeldt2001social,eveland2009political}. Of course, this information diffusion is fundamentally grounded in how people discuss and justify their political beliefs when talking to each other. A survey--especially if it is conducted face to face--could in theory be characterized as such a \textit{formalized} conversation between two individuals (\citealt{sudman1996thinking}; see also \citealt{grice1975logic,grice1978further}). How people discuss their beliefs in open-ended responses can therefore be informative for individual political competence as well as its crucial role in knowledge transmission through social interaction. 


\section*{Measuring Discursive Sophistication}

% OUTLINE MEASUREMENT %
% 1. How can we characterize in-depth processing in open-ended responses? We don't want to look at textual complexity, as other recent research has done.
% 2. It's about the speaker, not the recipient! This is were the literature on belief systems comes in! Theoretical accounts of political sophistication as the basis for elaborate and in-depth political reasoning
% 3. Derive the three dimensions conceptually, connect them to belief system literature -> survey example!
% 4.-6. Now we discuss how we can measure them in open-ended responses

% How can we characterize the level of sophistication in open-ended responses that engage in more in-dpeth processing? This is where the literature on belief systems comes in.
% Next, I will explore specific attributes that allow us to distinguish more or less elaborate reasoning in open-ended responses.
% If we To the extent that people's political sophistication and competence manifests itself in attitude expression 
% Recent studies in political science, for example, used measures based on the readability or comprehensibility to study the sophistication of political communication
% measuring the degree of elaborate reasoning in verbatim attitude expression

Assessing the complexity of written (or spoken) word has been the subject of longstanding research in linguistics and educational sciences, resulting in a multitude of available metrics. Recently, these measures caught the attention of political scientists who study different forms of elite communication. \citet{spirling2016democratization}, for example, uses a standard readability score based on the ratio of words per sentence and syllables per word to study the linguistic complexity of speeches in the British House of Commons over time. More recently, \citet{benoit2017measuring} expanded on previous metrics to develop a measure of comprehensibility that is more applicable in the realm of politics.
% \citet{spirling2016democratization}: The findings reveal that ministers started to use simple language in the parliament after suffrage was expanded in the middle nineteenth century---presumably in an effort to appeal to the enlarged voter base. 

These approaches--and especially the development of metrics specifically for political text--are very useful when studying elite communication. Yet, they share a critical commonality, namely that they focus on the \textit{comprehensibility} of text as a measure of complexity. In other words, sophistication is evaluated based on a recipient's ease to understand the message. Again, while this might be a reasonable approach when studying the effects of elite communication, the inference of interest outlined in this paper is markedly different. My focus is to examine verbatim attitude expression to assess the \textit{messenger's} degree of elaborate reasoning. The linguistic style of a message is therefore not of central concern so long as it is unrelated to the actual political content.\footnote{In fact, one might be concerned that pure linguistic complexity is too confounded by other factors such as a person's general verbosity or linguistic prowess to measure political sophistication of the speaker.} After all, being hard to comprehend does not necessarily imply that someone put a lot of thought into a statement.
% Reading level measures essentially focus on how hard it is to understand the author. This makes sense if we are primarily interested in the messaging aspect, for example when analyzing speeches of political elites. When it comes to individual levels of sophistication, a pure focus on linguistic patterns are less ideal.
% However, while these techniques are certainly useful to examine complexity in messaging by political elites, they may be highly confounded by personal verbosity and linguistic prowess. Instead of assessing linguistic style, we want to target the complexity in the actual content. Rather than measuring how a specific attitude is delivered, we want to focus on the the complexity in what is being said.
% The inference of interest is not how easy it is to understand someone, but rather how much thought went into what has been said. Both are clearly correlated, but they should not be assumed to be equivalent.
% comprehensibility of the text captures more of the linguistic ability independent of the underlying political content.

In contrast, this paper targets the underlying reasoning that gives rise to an utterance rather than simply measuring comprehensibility on the side of the recipient. Specifically, I leverage the content of open-ended responses in conjunction with the survey's structure to develop a measure of political sophistication. Consider for example a survey where respondents are prompted to describe their attitudes toward major presidential candidates and their parties in multiple open-ended items. Specifically, each question asks for either positive or negative considerations related to one of the parties or candidates. In developing a measure of political sophistication, we are ultimately interested in people's level of elaboration when justifying their preferences in such a set of open-ended responses. So how would a politically sophisticated person who engages in in-depth processing discuss her views compared to a less informed individual?

Previous theoretical accounts of political sophistication focus on the \textit{structure} of individual belief systems. For example, \citet{converse1964nature} emphasizes the importance of the level of conceptualization as the main characteristic of sophistication rather than isolated pieces of factual information. Similarly, \citet{tetlock1983cognitive,tetlock1993cognitive} uses the term \textsl{integrative complexity} to describe the degree to which considerations related to an issue are interconnected. \citet{luskin1987measuring} also defines political sophistication based on the structure of individual belief systems, arguing that they can vary on three separate dimensions: (1) their \textsl{size} -- i.e. the number of cognitions, (2) their \textsl{range} -- i.e. the dispersion of cognition over categories, and (3) their \textsl{constraint} -- i.e. the extent to which cognitions are interconnected in a meaningful way. Political sophistication, in turn, is seen as the conjunction of these dimensions: ``A person is politically sophisticated to the extent to which his or her [political belief system] is large, wide-ranging, and highly constrained.'' \citep[860]{luskin1987measuring}. An open-ended response based on elaborate reasoning should reflect this notion of complex belief systems. Unsurprisingly, Converse and others looked at open-ended responses in their first assessments of levels of conceptualization.
But we don't want to use manual coding!

Going back to the scenario of multiple open-ended questions about candidate preferences in a survey, the structure of individual political belief systems (i.e., size, range, and constraint) as well as the level of motivation to engage in more elaborate reasoning should be reflected in their verbatim responses. In the following, I discuss three different attributes of open-ended survey responses that should be indicative of sophistication in attitude expression.

First of all, sophisticated individuals should be able to elaborate more on their political attitudes. If people possess a large, wide-ranging, and constrained belief system, they should be able to recall a large number of \textit{considerations} related to political actors or issues. I rely on the structural topic model framework \citep{roberts2014structural} to extract the number of topics mentioned by each respondent in a survey.\footnote{See below for more information on the set of open-ended responses, pre-processing choices, as well as on the topic model specification.} First, denote $\mathcal{W}_i$ as the set of words contained in a response of individual $i$. Each word $w\in\mathcal{W}_i$ is assigned to a topic $t^* \in \{1,...,T\} $, such that $P(t^*|w,X_i) > P(t|w,X_i) \forall t\neq t^*$.\footnote{Note that $P(t|w,X_i)=\dfrac{P(w|t)P(t|X_i)}{P(w|X_i)}$. In the context of structural topic models, $X_i$ denotes the covariates used to predict individual topic prevalence \citep[see][for details]{roberts2014structural}.} In other words, each unique term in a response is assigned to the topic that has the highest likelihood of having generated that term, given the model. The set of topics that are mentioned by respondent $i$ across all words in $\mathcal{W}_i$ can then be denoted as $\mathcal{T}^*_i$ and the number of considerations can be written as:
\begin{equation}
\text{considerations}_i = \dfrac{|\mathcal{T}^*_i|}{\max|\mathcal{T}^*_i|}.
\end{equation}
The measure is re-scaled to range from zero to one by dividing raw count of topics by the maximum number of topics observed across individuals.

%There's a connection between the Benoit Google Scholar argument and the word choice measure, although with opposite conclusions...

However, sophisticated respondents should not only be able to mention a larger number of raw considerations when discussing politics. The level of sophistication should also be reflected in the \textit{word choice} describing the underlying issues. Individuals who possess a constrained system of beliefs should be more inclined to use terms that are highly descriptive of a given topic (e.g., the \textit{economy} or \textit{taxes}) rather than broad terms that could be attributed to any topic and are not clearly related to politics. Highly descriptive word choice is conceptualized as the sum of term likelihoods $P(w|t^*)$ given topic assignments over the entire set of words in $\mathcal{W}_i$:
\begin{equation}
\text{word choice}_i = \dfrac{\sum_{\mathcal{W}_i} P(w|t^*)}{\max\left[\sum_{\mathcal{W}_i} P(w|t^*)\right]}
\end{equation}
Again, the measure is re-scaled to range from zero to one by dividing all values by the empirical maximum observed across all individuals in the data.

% TODO: think of new label for opinionation

Lastly, sophisticated individuals should hold opinions about each political actor or policy that they are asked to discuss. Given a set of multiple open-ended probes focusing on different issues, sophisticates should be able to express their attitudes towards each question in terms of both approval or disapproval. Responses that reflect high levels of sophistication should therefore display a greater level of \textit{opinionation}, which is conceptualized as the diversity of relative lengths for each open-ended response (specified as the Shannon entropy):
\begin{equation}
\text{opinionation}_i = \dfrac{-\sum_{j=1}^J p_{ij} \ln p_{ij}}{\ln J}
\end{equation}
where $p_{ij}$ is the proportion of words in the response of individual $i$ to question $j\in \{1,...,J\}$ relative to the overall size of the individuals' response. The variable ranges from 0 (only one question was answered) to 1 (all questions were answered with the same word length per answer).

% TODO: mention factor analysis here, maybe add in appendix

Together, the three measures form a composite metric of sophistication in political attitude expression by calculating their respective average for each respondent. Like each individual component, the resulting \textit{discursive sophistication} score ranges from 0 to 1:
\begin{equation}
\text{discursive sophistication}_i = \tfrac{1}{3}(\text{considerations}_i + \text{word choice}_i + \text{opinionation}_i).
\end{equation}
Overall, a highly sophisticated individual can be expected to respond to a set of open-ended items by giving a more elaborate response that focuses on multiple considerations using terms that are highly descriptive of each topic and addresses his or her attitudes towards all relevant political actors or policies more or less equally.

Overall, differences in sophistication should be reflected in the way individuals describe and justify their political beliefs. Crucially, a measure of sophistication that is based on how individuals discuss their preferences in their own words can be directly applied in various settings to target specific political tasks such as choosing between candidates, parties, or policy propositions. Rather than having to devise a new set of questions that attempt to capture information necessary to make competent decisions, we can simply analyze how respondents elaborate on their related preferences in verbatim.

%\clearpage
\section*{An Overview of Data Sources and Open Ended Items}
% CUTS: This section should start on page 6

The measure of discursive sophistication is validated using multiple surveys employing different sets of open-ended questions. Each survey focuses on sophistication in the context of distinct political tasks, namely the evaluation of (1) candidates running for public office, (2) broad issue areas such as health care and gun legislation, and (3) policy referenda. The data sets and items used to compute discursive sophistication are briefly described below.\footnote{See Appendix~\ref{app:oeinfo} for descriptive information on open-ended responses in each dataset, structural topic model results, and individual components of discursive sophistication. Appendix~\ref{app:topicmodel} contains further details on pre-processing steps and modeling choices for the structural topic models as well as robustness checks, which include preText analyses proposed by \citet{denny2018text}. Lastly, Appendix~\ref{app:variables} provides information on the remaining variables included in the analyses.}


\subsection*{2012 \& 2016 American National Election Study}
The main analyses are based on the 2012 and 2016 wave of the American National Election Study (ANES), which consist of a representative survey of about 5000 adults in the months before the US Presidential election in each year. About 2000 respondents in both waves participated in face-to-face interviews while the remaining respondents filled out the survey online. For the purpose of the present analyses, I rely on the pooled datasets while controlling for differences in survey mode. The measure of discursive sophistication is based on open-ended questions in which respondents were asked in the pre-election wave of the survey to list anything in particular that they like/dislike about the Democratic/Republican party as well as anything that might make them vote/not vote for either of the Presidential candidates. They were probed by the interviewer asking ``anything else?'' until the respondent answered ``no.'' Overall, there are a total number of 8 open-ended responses where individuals described their beliefs and attitudes towards political actors. Individuals who did not respond to all of the open-ended items (420 in 2012; 204 in 2016), or who responded in Spanish (228 in 2012; 43 in 2016), are excluded from the analysis.


\subsection*{2015 YouGov Survey}
In order to replicate and extend the main analyses, I rely on a separate nationally representative survey employing an alternative set of open-ended responses. The data was collected by YouGov in December 2015 and contains responses of 1000 U.S. citizens.\footnote{See \citet{clifford2018disgust} for details on the study.} As part of this study, respondents were asked to describe their attitudes towards two prominent political issues that were discussed frequently in the media. First, they were asked in a closed format whether they favor or oppose stricter gun laws. Subsequently, they were asked to respond to the following two questions:
\begin{itemize}\setlength\itemsep{0em}
\item Still thinking about the question you just answered, what thoughts came to mind while you were answering that question? Please try to list everything that came to mind.
\item Thinking about the mass shootings that have occurred in the U.S. in the last few years, what factors do you think are responsible for the shootings?
\end{itemize}
Second, the respondents reported on their attitudes towards the Affordable Care Act in a closed format and were then asked to elaborate in their own words by answering the following questions:
\begin{itemize}\setlength\itemsep{0em}
\item Still thinking about the question you just answered, what thoughts came to mind while you were answering that question? Please try to list everything that came to mind.
\item For decades, experts have observed that the United States spends far more per person on health care than any other country. However, the U.S. falls behind on most measures of health care outcomes, such as life expectancy. What factors do you think are responsible for the state of our health care system?
\end{itemize}
Here, discursive sophistication is computed based on the verbatim responses to the four preceding questions using the same procedures described above. Compared to the open-ended likes/dislikes items included in the 2012 and 2016 ANES, the questions directly address considerations related to specific policy issues that were prominent in the political discourse at the time of the survey. Respondents who did not provide an answer to any of the open-ended questions were removed from the analysis (48).


\subsection*{Swiss Referendum Survey}
Lastly, I examine survey data on Swiss citizens justifying their vote choices on multiple referenda used in a recent analysis by \citet{colombo2016justifications}. The author compiled a data set of cross-sectional surveys administered in Switzerland after national popular votes on multiple policy propositions. The original surveys were conducted as representative samples after each of thirty-four national policy votes that were held between 2008 and 2012 resulting in a total of about 27,000 observations. However, respondents were only asked to justify their decision for or against a given proposition in verbatim if they participated in the vote in the first place. As such, about 5,000 individuals in the data set did not provide an open-ended response. The remaining respondents were asked to describe the main reason as well as additional justifications for their decision in two separate items. As before, discursive sophistication is computed based on verbatim responses to both questions.
% QUESTION wording for Swiss study?



\section*{A First Look at Discursive Sophistication}

Before turning to the validation, I begin by directly comparing discursive sophistication to alternative metrics of political knowledge in the 2012 and 2016 ANES. The standard approach to measuring political knowledge in surveys is to ask a set of factual questions about political institutions. The ANES surveys include such a basic item battery, inquiring for example about the number of times an individual can be elected President of the United States, or how the current U.S. federal budget deficit compares to the deficit in the 1990s. I combine responses on these items to form an additive index of \textit{factual knowledge} about politics. As an additional benchmark, I consider \textit{interviewer assessments} of each respondent's political sophistication (see \citealt{bartels2005homer} for an example of a study that relies on interviewer assessments; but cf. \citealt{ryan2011accuracy}).\footnote{Interviewer assessments were only recorded in the face-to-face sample of the ANES.}

\begin{figure*}[h]
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/anes2012_corplot.pdf}
        \caption{2012 ANES}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/anes2016_corplot.pdf}
        \caption{2016 ANES}
    \end{subfigure}
    \caption[Correlation matrix of discursive sophistication and conventional political knowledge metrics]{Correlation matrix of discursive sophistication and conventional political knowledge metrics. The plots on the diagonal display univariate densities for each variable. The panels in the lower triangular display the scatter plot of two measures as well as a linear fit. The upper triangular displays the correlation coefficient. All correlations reported are statistically significant with $p<.05$.}\label{fig:corplot}
\end{figure*}

Figure~\ref{fig:corplot} compares discursive sophistication to the conventional knowledge metrics for both surveys. Each figure presents scatterplots between individual measures (lower triangular), univariate densities (diagonal), and correlation coefficients (upper triangular). The measure of discursive sophistication is positively correlated with both conventional metrics while capturing some additional variation. Interestingly, there is a stronger correlation between discursive sophistication and interviewer evaluations than between factual knowledge and interviewer evaluations ($r=.45$ vs. $r=.31$ in 2012, and $r=.36$ vs. $r=.23$ in 2016). The open-ended measure therefore captures characteristics that influence subjective assessments of sophistication. Interviewers certainly form their impressions throughout the entire survey, but a respondent's verbatim answers seems to be more influential for subsequent knowledge assessments than a respondent's performance on the factual knowledge questions.

Overall, while discursive sophistication and the alternative measures are clearly correlated, the relationship between each metric is far from perfect. To provide some intuition as to whether the variation in discursive sophistication is theoretically meaningful, I present an example of open-ended responses of two individuals in the 2016 ANES who identified as Republicans and scored equally on the factual knowledge score (3 out of 4 correct responses), but varied highly in discursive sophistication. The results are presented in Table~\ref{tab:ex1}.

\begin{table}[ht]\footnotesize\centering
\begin{tabular}{l|p{6.3cm}|p{6.3cm}}
\toprule
	& A: Low Sophistication Response & B: High Sophistication Response \\ \midrule
Clinton (+)		& 																& Politician. \\\hdashline
Clinton (-)		& The fact that she has links to Al-Qaeda. 						& Caught in lies. \\\hdashline
Trump (+)		& 																& Says what he thinks. \\\hdashline
Trump (-)		& He is going to start a civil war. I feel like he is racist. 	& Reality TV star, poor businessman \\\hdashline
Democrats (+)	& 																& Middle class minded. \\\hdashline
Democrats (-)	& 																& Too many handouts. \\\hdashline
Republicans (+)	& 																& Economic growth conscious. \\\hdashline
Republicans (-)	& 																& For the big business. \\\midrule
Disc. Soph. 	& 0.162 														& 0.461 \\\bottomrule
 \end{tabular}
\caption[Example of open-ended responses for low and high scores on discursive sophistication]{Example of open-ended responses for low and high scores on discursive sophistication with equal factual knowledge scores (3 out of 4 correct responses). Column A displays the verbatim responses of an individual who scored low on discursive sophistication and column B displays the verbatim responses of an individual who scored high on the open-ended measure. Each row represents one of the likes/dislikes items included in the analysis. Note that the responses in this table were slightly redacted for readability (spelling errors removed, etc.).}\label{tab:ex1}
\end{table}

Each row in the table represents one of the open-ended responses (like/dislike for each candidate/party). Column A displays the responses of an individual who scored low on discursive sophistication and column B displays the responses of a high scoring individual. Cells are empty if a respondent refused to provide a response. Even though both individuals are measured to have equal factual political knowledge, there are systematic differences in their response behavior that can be attributed to their political sophistication. Overall, respondent A provided a less elaborate response, only focused on a narrow range of issues, and only reported attitudes on two items. Irrespective of whether one agrees with the specific statements or whether they are factually accurate (e.g., Clinton's connection to Al-Qaeda), A's response pattern is suggestive of a less sophisticated political belief system and a lower level of motivation to engage in in-depth reasoning about both parties and candidates. Overall, this initial result suggests that the variation in discursive sophistication captures meaningful differences in response behavior that overlaps with traditional knowledge metrics while displaying some unique variation. The following sections will show that this variation is also politically consequential.



\section*{Discursive Sophistication and Political Competence}

I validate the measure of discursive sophistication by directly examining its effects on individual competences to perform political tasks in modern democracies \citep[cf.][]{lupia2006elitism,lupia2015uninformed}. More specifically, I consider the potential role of political sophistication in promoting (1) engagement and participation in politics, (2) the ability to incorporate new information, and (3) well-justified policy preferences. In the following, each point will be addressed using one of the three data sets described above.
% (5) vote choices that are consistent with underlying interests


\subsection*{Engagement and Participation in Politics}
Political sophistication is often argued to promote individual engagement and participation in politics. In fact, factual knowledge items have been validated in the past based on their strong relationship with outcomes such as turnout and other forms of participation \citep[230--233]{lupia2015uninformed}. Figure~\ref{fig:knoweff} compares the effects of discursive sophistication and factual knowledge in the 2012 and 2016 ANES on four dependent variables related to political engagement: turnout, non-conventional participation, internal efficacy, and external efficacy. The model predicting turnout is estimated via logistic regression while the estimates for the three remaining dependent variables are based on OLS. Each model equation includes both sophistication measures while controlling for gender, education, income, age, race, church attendance, survey mode (face-to-face vs. online), as well as the Wordsum vocabulary score measuring verbal intelligence.

\begin{figure}[h]\centering
\includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/knoweff_pres.pdf}
\caption[Effects of sophistication on turnout, non-conventional participation, internal efficacy, and external efficacy in the 2012 and 2016 ANES]{Effects of sophistication on turnout, non-conventional participation, internal efficacy, and external efficacy in the 2012 and 2016 ANES. For each dependent variable, the figure displays the change in expected values after increasing each sophistication measure from -1 to +1 standard deviation from its mean (including 95\% confidence intervals). Model estimates are based on logistic regression (turnout) or OLS (non-conventional participation, internal efficacy, external efficacy). Both sophistication measures are included simultaneously while controlling for gender, education, income, age, race, church attendance, survey mode, and Wordsum vocabulary scores. Full model results are displayed in the appendix, Tables~\ref{tab:knoweff2012} and \ref{tab:knoweff2016}.}\label{fig:knoweff}
\end{figure}

Each panel displays the expected difference in the respective dependent variable for a two standard deviation increase in each sophistication measure, while holding all other variables constant at their means. Overall, discursive sophistication is a stronger predictor of turnout, non-conventional participation, as well as (to a lesser extent) internal and external efficacy. In the 2012 ANES, the positive effect of factual knowledge on participation is statistically indistinguishable from zero when controlling for discursive sophistication. Furthermore, there is a negative effect of factual knowledge on external efficacy in the 2016 ANES. In contrast, the positive effect of discursive sophistication on external efficacy is more consistent with previous research. Considering these initial results, a potential concern may be that discursive sophistication is confounded by personality characteristics that influence verbatim response patterns as well as engagement. Appendix~\ref{app:personality} provides additional analyses controlling for such factors that might drive verbosity (extraversion and being reserved) as well as individual response length itself. The substantive conclusions remain unchanged.


\subsection*{Incorporation of New Information}
Competent citizens should not only engage in politics but are also expected to be sufficiently informed about the issues of the day. As such, they have to be attentive to their media environments and incorporate potentially relevant new information about parties, office-holders, and policies. Indeed, \citet{zaller1990political,zaller1992nature} and others argue that tests of factual information about politics are the best available proxy for awareness. In this analysis I draw on the 2015 YouGov study to explore whether discursive sophistication or factual knowledge serves as a better predictor of people's ability to incorporate new information from media sources. As part of the survey, respondents were asked to read a newspaper article about a fictional infectious disease and were subsequently asked to answer questions about information provided in the article (e.g. regarding symptoms, modes of contraction etc.). I compute an additive index counting the pieces of information that were correctly recalled (\textit{information retrieval}) as a measure of the ability to retrieve information from a news article on a non-partisan issue that is related to public health policies. 

\begin{figure}[h]\centering
\includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/yg_disease.pdf}
\caption[Expected information retrieval in the 2015 YouGov Study as a function of political sophistication]{Expected information retrieval in the 2015 YouGov Study as a function of political sophistication (including 95\% confidence intervals). Estimates are based on a linear regression model controlling for education, income, age, church attendance, gender, and race. Full model results are displayed in the appendix, Table~\ref{tab:yg_disease}.}\label{fig:yg_disease}
\end{figure}

Figure~\ref{fig:yg_disease} displays the relationship between political sophistication and disease information retrieval in the 2015 YouGov study. Estimates are based on a linear regression model controlling for education, income, age, church attendance, gender, and race. As a benchmark for discursive sophistication, I again consider the effect of factual knowledge based on a battery of eight items similar to the knowledge questions in the ANES. Both discursive sophistication as well as factual knowledge increase the amount of information individuals are able to recall from a news article discussing a fictional disease. Similar to the previous results, the effects are stronger for discursive sophistication than for factual knowledge scores. The degree to which citizens discuss their own political beliefs in a more elaborate manner is not only a stronger predictor of political engagement but also serves as a better proxy for the ability to incorporate new information about a non-partisan issue.


\subsection*{Well-Justified Policy Preferences}
Beyond the ability of incorporating new information, competent citizens should be knowledgeable about the underlying policies themselves and be able to justify their own preferences. Here, I explore the extent to which high levels of discursive sophistication correspond to well-justified policy preferences in open-ended responses. As mentioned above, the Swiss surveys included items that asked respondents to explain why they voted in favor or against a given proposition in multiple policy referenda. To corroborate the face validity of discursive sophistication, I examine whether the measure is related to Colombo's \citeyearpar{colombo2016justifications} manual coding of the respondents' \textit{level of justification}, which assessed the content, elaboration, and complexity of open-ended responses.

The results are presented in Figure~\ref{fig:swiss_ggridges}. Since the Swiss post-referendum surveys were conducted in three different languages (German, French, and Italian), I computed the measure of discursive sophistication separately for each group of respondents. The figure displays the distribution of discursive sophistication for each level of justification coded by \citet{colombo2016justifications} as well as the correlation coefficients for both respective variables. Across all three language groups, discursive sophistication is systematically higher among respondents with the highest level of justification and both measures are positively correlated ($r=0.29, 0.25$, and $0.35$, respectively). The proposed measure of discursive sophistication therefore shows a high degree of correspondence with individual levels of justification assessed by independent manual coders.

\begin{figure}[h]\centering
\includegraphics[scale=1]{/data/Dropbox/Uni/Projects/2016/knowledge/fig/swiss_ggridges.pdf}
\caption[Discursive sophistication and manually coded level of justification in Swiss post-referendum surveys]{Discursive sophistication and manually coded level of justification \citep{colombo2016justifications} in Swiss post-referendum surveys. The plot compares kernel densities of discursive sophistication for each manually coded level of justification.}\label{fig:swiss_ggridges}
\end{figure}

To summarize, the results presented thus far indicate that discursive sophistication shares common characteristics with factual political knowledge measures. Compared to conventional metrics, the proposed measure performs as least as well as a predictor of essential competences that allow citizens to engage successfully in politics. In fact, discursive sophistication is a stronger predictor of certain outcomes (such as different forms of political participation) than conventional knowledge scores. In the following, I turn to an application to illustrate how discursive sophistication can help refine important previous insights from the literature on political knowledge.

\clearpage
\section*{Application: The Gender Gap in Political Knowledge}

A common finding in public opinion research is the fact that women have lower levels of observed political knowledge than men. For example, \citet{verba1997knowing} report that women score lower on political information, interest, and efficacy, which decreases their respective levels of political participation. Since gender differences in political information and interest can only partly be explained by resource-related factors such as individual levels of education, the authors diagnose a ``genuine difference in the taste for politics'' between men and women, which they suspect to be driven largely by socialization \citep[see also][]{wolak2011roots}. Indeed, \citet[117]{dow2009gender} describes the systematic gender differences in knowledge ``one of the most robust findings in the study of political behavior.''

The discussion revolving around this apparent gender gap is closely intertwined with the methodological debate about measuring political knowledge. For example, \citet{mondak2004knowledge} suggest that women are more likely to report that they do not know the answer to a recall question whereas men are more inclined to guess. Correcting for the systematic differences in the propensity to guess, however, mitigates the gender gap in knowledge but does not eliminate it completely \citep[see also][]{lizotte2009explaining}. Other aspects of the survey context have been shown to affect gender differences in political knowledge. For example, \citet{mcglone2006stereotype} present evidence that the gender gap is exacerbated in an environment that induces stereotype threat, for example if women are aware of the fact that the study focuses on gender differences or if they are interviewed by a male interviewer. However, gender differences are not only induced by \textit{how} researchers ask their questions, but also by the question \textit{content} itself. For example, \citet{dolan2011women} argues that the gap can be closed by focusing on gender-relevant political knowledge items such as information about women's representation in the federal government \citep[see also][]{graber2001processing,fraile2014does,jerit2017revisiting}. Similarly, \citet{stolle2010women} report that the gender gap disappears when people are asked about more practical issues related to the government (e.g., benefits and services).

Overall, the gender gap has been shown to be influenced by how we ask for political information in surveys, as well as the kind of knowledge that is required for a correct response. Indeed, a comprehensive cross-national analysis of election studies in 47 countries between 1996 and 2011 suggests that question format and content account for large portions of the variance of gender disparities in political knowledge \citep{fortin2016cross}.


\subsection*{Descriptive Results}
How do men and women compare on the different metrics of political sophistication in the surveys analyzed in the present study? Figure~\ref{fig:meandiff} displays the average levels of discursive sophistication as well as conventional metrics comparing both genders. While we observe a sizable and statistically significant gender gap for factual knowledge in both ANES surveys, this difference disappears for discursive sophistication. These results are replicated in the 2015 YouGov survey. As before, we observe a significant gender gap in factual knowledge which disappears using the discursive measure. Of course, it is important to ask whether this absence of a gender gap in discursive sophistication is theoretically meaningful or rather an artifact of the measurement approach itself. 

One way to investigate this question is to explore gender differences in discursive sophistication using the \citet{colombo2016justifications} data and comparing them to her manually coded measure. That way, we can not only examine whether the lack of a gender gap in discursive sophistication replicates using an additional survey, but also check whether there is an equivalent lack of gender differences in Colombo's alternative measure of citizen competence in direct democracies. If discursive sophistication captures a person's motivation to undertake in-depth reasoning and form quality opinions (and assuming these characteristics do not differ by gender), there should be no difference between men and women on either metric (discursive sophistication and Colombo's measure).  As shown in the bottom row of Figure~\ref{fig:meandiff} there are indeed no significant gender differences on \textit{both} metrics across all three languages in the Swiss referendum surveys. The absence of a gender gap is consistent whether open-ended responses are coded manually or using the proposed measure of discursive sophistication.

\begin{figure}[h]\centering
\includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/meandiff.pdf}
\caption[The gender gap in political sophistication]{The gender gap in political sophistication. The figures display mean levels of sophistication for each measure comparing men and women (including 95\% confidence intervals). Gender differences in factual knowledge in the 2012/2016 ANES and 2015 YouGov survey (top row) are statistically significant with $p<.05$. Gender differences in discursive sophistication and manually coded levels of justification \citep{colombo2016justifications} are not statistically significant.}\label{fig:meandiff}
\end{figure}


\subsection*{Controlling for Alternative Explanations}
Prior research suggests that at least part of the gender gap in political knowledge can be attributed to real discrepancies in resources and engagement. To the extent that differences between men and women can be explained by these underlying factors, they are less likely to be an artifact of the measurement of knowledge itself. Accordingly, we need to control for determinants of political knowledge to provide a more comprehensive examination of the veracity of observed gender differences. Figure~\ref{fig:determinants} displays estimated effects of various potential common determinants of factual knowledge and discursive sophistication on both measures. Previous studies consistently showed that political information levels are positively related to high media exposure, frequent political discussions, education, and income. Furthermore, I include age, race, church attendance, and survey mode (face-to-face vs. online) as additional control variables.

\begin{figure}[h]\centering
\includegraphics{/data/Dropbox/Uni/Projects/2016/knowledge/fig/determinants.pdf}
\caption[Common determinants of political sophistication]{Common determinants of political sophistication. Estimates are OLS regression coefficients with 95\% confidence intervals. Dependent variables are discursive sophistication as well as factual political knowledge. Full model results are displayed in the appendix, Tables~\ref{tab:determinants_anes} and \ref{tab:determinants_yg}.}\label{fig:determinants}
\end{figure}

After controlling for common determinants, discursive sophistication again reveals no significant differences between men and women in both ANES surveys as well as the 2015 YouGov study. The gender gap in factual political knowledge, however, persists and is substantively as well as statistically significant after controlling for various resource-related factors. Even though women do not perform as well as men on political quizzes, they do not differ substantially in complexity and sophistication when they describe their political preferences. The effects of the remaining variables are quite similar across both measures and different surveys. Knowledge and sophistication is significantly higher among respondents who are more exposed to political news media, discuss politics frequently, are more educated, and have higher income.\footnote{An interesting deviation, however, is the effect of survey mode in the 2012 and 2016 ANES. Respondents in online surveys score significantly higher on factual knowledge than in face-to-face interviews. This difference can be attributed to the fact that individuals are able to look up answers for factual knowledge questions while taking an online survey \citep[cf.][]{clifford2016cheating}. For discursive sophistication, on the other hand, individuals perform better in the face-to-face survey. Open-ended answers in online surveys may be less elaborate because respondents have to manually type their responses.} Overall, the finding that determinants of political sophistication are consistent across models lends additional validity to the open-ended measure.

To summarize, we only observe a significant gender gap when looking at conventional recall-based measures, a result that previous research (at least partly) attributed to the content (i.e., focusing on issues that are less relevant to women) and format (i.e., stereotype-threat and guessing) of the question batteries. When using the alternative measure---discursive sophistication---any evidence for systematic differences between men and women disappears.


\subsection*{Explaining the (Lack of the) Gender Gap}
If it is the case that women are able to close the gender gap in discursive sophistication because they are able to focus on different considerations that are salient to them when discussing their political preferences, we should observe systematic variation in the issues men and women discuss in open-ended responses. Based on the structural topic model used to compute discursive sophistication, I now examine the subset of topics that showed the largest absolute gender difference in topic prevalence in the 2012 and 2016 ANES. The results are displayed in Figure~\ref{fig:stm_gender}.

\begin{figure}[h]\centering
\includegraphics[width=\textwidth]{/data/Dropbox/Uni/Projects/2016/knowledge/fig/stm_gender.pdf}
\caption[Gender differences in topic proprtions in open-ended responses]{Gender differences in topic proportions in open-ended responses based on the structural topic model used to compute discursive sophistication (including 95\% confidence intervals). Coefficients indicate the difference in predicted topic prevalence among men and women; positive values indicate higher prevalence among women. Labels are based on the five highest probability terms related to the topic.
%Full model results are displayed in the appendix, Table~\ref{tab:determinants}
}\label{fig:stm_gender}
\end{figure}

Positive coefficients indicate that women are more likely than men to mention a given topic, and vice versa. As such, the top six topics are more prevalent among men and the bottom six have a higher probability to be mentioned by women. Each coefficient is labeled with the five highest probability terms related to the topic to illustrate its content. Across both ANES studies, women were less likely than men to discuss foreign affairs, economic issues, or the Supreme Court. Instead, they focused on issues related to women's rights, equality, or health care. The considerations taken into account by women when discussing their political preferences are therefore clearly different from men's and---crucially---the issues raised by men happen to be more aligned with what political scientists often deem as necessary information (i.e., pertaining to the economy, institutions, elites, etc.). Yet, from a normative perspective, there is no reason to assume that one set of issues should be more important for citizens when forming their political preferences and making competent voting decisions.

% TODO: elaborate on the explanations for the lack of the gender gap


\section*{Conclusion}
% What is a competent citizen? One who has good reasons for his or her attitudes... we can measure that when examining how repondents talk about their political beliefs.

Political scientists should worry less about pure levels of \textit{factual knowledge} and instead focus on the necessary conditions for individuals to make \textit{competent} decisions. Competence in the context of political decision-making and voting requires citizens to hold informed attitudes about their representatives. Factual knowledge about political institutions might be a useful proxy for competence in certain scenarios. However, it cannot address directly whether individuals hold well-considered opinions about political actors they try to hold accountable. In comparison, the measure of discursive sophistication proposed here is agnostic about the specific contents of people's beliefs, but directly captures the complexity of individual attitude expression. Furthermore, it can be easily applied to assess sophistication in any decision-making context (such as a policy referendum or a local election) by fielding targeted open-ended questions related to the relevant underlying beliefs and preferences.

The findings presented in this paper show that conventional knowledge indices and the discursive measure share a substantial amount of variance. However, they are far from being identical and capture different aspects of sophistication. Most importantly, using the discursive measure, evidence for the gender gap commonly reported using factual knowledge scales disappears. Women might know fewer facts about political institutions, but they do not differ substantively in the complexity of their expressed political beliefs. The fact that women perform just as well as men on discursive sophistication across various surveys can be attributed to the fact that they focus on different considerations when evaluating political parties and candidates. This issue has long been recognized in the literature \citep[e.g.,][]{graber2001processing,dolan2011women}, but it cannot be properly addressed while relying exclusively on off-the-shelf political knowledge batteries. As discussed at the outset, \citet{zaller1992nature} and others made the argument that testing for factual information provides the best measure of political awareness as it captures ``what has actually gotten into people's minds, which, in turn, is critical for intellectual engagement with politics'' (21). The results presented in this paper suggest that a direct examination of open-ended responses provides a viable alternative approach.

% DISCUSS: highlight the advantages of the measure, also regarding the ability to find policy areas that are less gender biased.

% DISCUSS: mention disadvantages of the method, clearly state that it is not to be viewed as a replacement but rather a substitute for political knowledge questions.

% DISCUSS manual coding as alternative? However, manual coding of open-ended responses as employed by \citet{colombo2016justifications} is not always feasible in the context of large-scale surveys, since it can be labor-intensive and requires extensive contextual knowledge, such as high levels of language proficiency.\footnote{The Swiss surveys in Colombo's \citeyearpar{colombo2016justifications} study were conducted in three different languages: German, French, and Italian.} Furthermore, knowledge assessments can be biased by the level of political agreement between individuals \citep{ryan2011accuracy}. As such, I present an alternative approach that relies on quantitative text-analysis methods and can be applied in multiple contexts and different languages.